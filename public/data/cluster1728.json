{
    "Event": "SparkListenerLogStart",
    "Spark Version": "3.3.2"
}
{
    "Event": "SparkListenerResourceProfileAdded",
    "Resource Profile Id": 0,
    "Executor Resource Requests": {
        "cores": {
            "Resource Name": "cores",
            "Amount": 1,
            "Discovery Script": "",
            "Vendor": ""
        },
        "memory": {
            "Resource Name": "memory",
            "Amount": 1024,
            "Discovery Script": "",
            "Vendor": ""
        },
        "offHeap": {
            "Resource Name": "offHeap",
            "Amount": 0,
            "Discovery Script": "",
            "Vendor": ""
        }
    },
    "Task Resource Requests": {
        "cpus": {
            "Resource Name": "cpus",
            "Amount": 1.0
        }
    }
}
{
    "Event": "SparkListenerBlockManagerAdded",
    "Block Manager ID": {
        "Executor ID": "driver",
        "Host": "node86",
        "Port": 38728
    },
    "Maximum Memory": 455501414,
    "Timestamp": 1680601038375,
    "Maximum Onheap Memory": 455501414,
    "Maximum Offheap Memory": 0
}
{
    "Event": "SparkListenerEnvironmentUpdate",
    "JVM Information": {
        "Java Home": "/home/chenhao/libs/jdk11",
        "Java Version": "11.0.16.1 (Oracle Corporation)",
        "Scala Version": "version 2.13.8"
    },
    "Spark Properties": {
        "spark.eventLog.enabled": "true",
        "spark.driver.port": "42755",
        "spark.jars": "file:/home/chenhao/workspace/SparkTemplate-1.3-jar-with-dependencies.jar",
        "spark.driver.supervise": "false",
        "spark.app.name": "WordCount",
        "spark.submit.pyFiles": "",
        "spark.app.submitTime": "1680601033624",
        "spark.submit.deployMode": "cluster",
        "spark.master": "spark://node85:7077",
        "spark.eventLog.dir": "/home/chenhao/logs/events",
        "spark.executor.cores": "1",
        "spark.app.id": "app-20230404174343-0001",
        "spark.executor.extraJavaOptions": "-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED",
        "spark.driver.host": "node86",
        "spark.scheduler.mode": "FIFO",
        "spark.rpc.askTimeout": "10s",
        "spark.streaming.kafka.maxRatePerPartition": "200000",
        "spark.app.startTime": "1680601037564",
        "spark.executor.id": "driver",
        "spark.driver.extraJavaOptions": "-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED",
        "spark.app.initial.jar.urls": "spark://node86:42755/jars/SparkTemplate-1.3-jar-with-dependencies.jar"
    },
    "Hadoop Properties": {
        "hadoop.service.shutdown.timeout": "30s",
        "yarn.resourcemanager.amlauncher.thread-count": "50",
        "yarn.nodemanager.numa-awareness.numactl.cmd": "/usr/bin/numactl",
        "fs.viewfs.overload.scheme.target.o3fs.impl": "org.apache.hadoop.fs.ozone.OzoneFileSystem",
        "yarn.timeline-service.timeline-client.number-of-async-entities-to-merge": "10",
        "hadoop.security.kms.client.timeout": "60",
        "yarn.resourcemanager.application-tag-based-placement.enable": "false",
        "yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds.min": "3600",
        "yarn.app.mapreduce.am.job.task.listener.thread-count": "30",
        "yarn.nodemanager.node-attributes.resync-interval-ms": "120000",
        "yarn.nodemanager.container-log-monitor.interval-ms": "60000",
        "fs.viewfs.overload.scheme.target.gs.impl": "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS",
        "fs.s3a.retry.limit": "7",
        "mapreduce.jobhistory.loadedjobs.cache.size": "5",
        "yarn.sharedcache.enabled": "false",
        "fs.s3a.connection.maximum": "96",
        "fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem",
        "yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms": "1000",
        "hadoop.http.authentication.kerberos.principal": "HTTP/_HOST@LOCALHOST",
        "mapreduce.jobhistory.loadedjob.tasks.max": "-1",
        "mapreduce.framework.name": "local",
        "yarn.sharedcache.uploader.server.thread-count": "50",
        "yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern": "^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$",
        "tfile.fs.output.buffer.size": "262144",
        "hadoop.security.groups.cache.background.reload.threads": "3",
        "yarn.resourcemanager.webapp.cross-origin.enabled": "false",
        "fs.AbstractFileSystem.ftp.impl": "org.apache.hadoop.fs.ftp.FtpFs",
        "hadoop.registry.secure": "false",
        "hadoop.shell.safely.delete.limit.num.files": "100",
        "mapreduce.job.acl-view-job": " ",
        "fs.s3a.s3guard.ddb.background.sleep": "25ms",
        "fs.s3a.s3guard.ddb.table.create": "false",
        "fs.viewfs.overload.scheme.target.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem",
        "mapreduce.shuffle.pathcache.expire-after-access-minutes": "5",
        "mapreduce.input.fileinputformat.split.minsize": "0",
        "yarn.resourcemanager.container.liveness-monitor.interval-ms": "600000",
        "yarn.resourcemanager.client.thread-count": "50",
        "fs.viewfs.overload.scheme.target.http.impl": "org.apache.hadoop.fs.http.HttpFileSystem",
        "yarn.nodemanager.amrmproxy.interceptor-class.pipeline": "org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor",
        "yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size": "10485760",
        "yarn.nodemanager.admin-env": "MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX",
        "yarn.resourcemanager.node-removal-untracked.timeout-ms": "60000",
        "mapreduce.am.max-attempts": "2",
        "hadoop.security.kms.client.failover.sleep.base.millis": "100",
        "yarn.nodemanager.amrmproxy.enabled": "false",
        "yarn.timeline-service.entity-group-fs-store.with-user-dir": "false",
        "io.seqfile.compress.blocksize": "1000000",
        "yarn.nodemanager.runtime.linux.docker.allowed-container-runtimes": "runc",
        "yarn.resourcemanager.nodemanagers.heartbeat-interval-slowdown-factor": "1.0",
        "yarn.sharedcache.checksum.algo.impl": "org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl",
        "mapreduce.reduce.shuffle.fetch.retry.interval-ms": "1000",
        "mapreduce.task.profile.maps": "0-2",
        "yarn.scheduler.include-port-in-node-name": "false",
        "mapreduce.jobhistory.webapp.https.address": "0.0.0.0:19890",
        "yarn.node-labels.fs-store.impl.class": "org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore",
        "hadoop.http.authentication.signature.secret.file": "*********(redacted)",
        "hadoop.jetty.logs.serve.aliases": "true",
        "yarn.sharedcache.webapp.address": "0.0.0.0:8788",
        "fs.s3a.select.input.csv.quote.escape.character": "\\\\",
        "fs.viewfs.overload.scheme.target.swift.impl": "org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem",
        "hadoop.security.group.mapping.ldap.posix.attr.gid.name": "gidNumber",
        "ipc.client.fallback-to-simple-auth-allowed": "false",
        "yarn.nodemanager.resource.memory.enforced": "true",
        "yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.enable-batch": "false",
        "yarn.client.failover-proxy-provider": "org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider",
        "yarn.nodemanager.collector-service.address": "${yarn.nodemanager.hostname}:8048",
        "fs.trash.checkpoint.interval": "0",
        "mapreduce.job.map.output.collector.class": "org.apache.hadoop.mapred.MapTask$MapOutputBuffer",
        "yarn.resourcemanager.node-ip-cache.expiry-interval-secs": "-1",
        "yarn.resourcemanager.placement-constraints.handler": "disabled",
        "yarn.timeline-service.handler-thread-count": "10",
        "yarn.resourcemanager.max-completed-applications": "1000",
        "yarn.nodemanager.aux-services.manifest.enabled": "false",
        "yarn.resourcemanager.system-metrics-publisher.enabled": "false",
        "yarn.resourcemanager.placement-constraints.algorithm.class": "org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.DefaultPlacementAlgorithm",
        "yarn.resourcemanager.delegation.token.renew-interval": "*********(redacted)",
        "yarn.sharedcache.nm.uploader.replication.factor": "10",
        "hadoop.security.groups.negative-cache.secs": "30",
        "yarn.app.mapreduce.task.container.log.backups": "0",
        "mapreduce.reduce.skip.proc-count.auto-incr": "true",
        "yarn.timeline-service.http-authentication.simple.anonymous.allowed": "true",
        "ha.health-monitor.check-interval.ms": "1000",
        "yarn.nodemanager.runtime.linux.runc.host-pid-namespace.allowed": "false",
        "hadoop.metrics.jvm.use-thread-mxbean": "false",
        "ipc.[port_number].faircallqueue.multiplexer.weights": "8,4,2,1",
        "yarn.acl.reservation-enable": "false",
        "yarn.resourcemanager.store.class": "org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore",
        "yarn.app.mapreduce.am.hard-kill-timeout-ms": "10000",
        "yarn.resourcemanager.nodemanagers.heartbeat-interval-scaling-enable": "false",
        "yarn.resourcemanager.nodemanagers.heartbeat-interval-ms": "1000",
        "yarn.nodemanager.windows-container.cpu-limit.enabled": "false",
        "yarn.scheduler.configuration.leveldb-store.path": "${hadoop.tmp.dir}/yarn/system/confstore",
        "mapreduce.map.skip.proc-count.auto-incr": "true",
        "fs.s3a.committer.name": "file",
        "yarn.webapp.xfs-filter.enabled": "true",
        "yarn.resourcemanager.scheduler.address": "${yarn.resourcemanager.hostname}:8030",
        "yarn.node-labels.enabled": "false",
        "yarn.resourcemanager.webapp.ui-actions.enabled": "true",
        "fs.s3a.etag.checksum.enabled": "false",
        "yarn.nodemanager.container-metrics.enable": "true",
        "ha.health-monitor.rpc.connect.max.retries": "1",
        "yarn.timeline-service.client.fd-clean-interval-secs": "60",
        "hadoop.common.configuration.version": "3.0.0",
        "fs.s3a.s3guard.ddb.table.capacity.read": "0",
        "yarn.nodemanager.remote-app-log-dir-suffix": "logs",
        "yarn.nodemanager.container-log-monitor.dir-size-limit-bytes": "1000000000",
        "yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed": "false",
        "file.blocksize": "67108864",
        "hadoop.http.idle_timeout.ms": "60000",
        "hadoop.registry.zk.retry.ceiling.ms": "60000",
        "yarn.sharedcache.store.in-memory.initial-delay-mins": "10",
        "mapreduce.jobhistory.principal": "jhs/_HOST@REALM.TLD",
        "mapreduce.task.profile.reduces": "0-2",
        "hadoop.zk.num-retries": "1000",
        "fs.viewfs.overload.scheme.target.hdfs.impl": "org.apache.hadoop.hdfs.DistributedFileSystem",
        "seq.io.sort.mb": "100",
        "yarn.scheduler.configuration.max.version": "100",
        "yarn.timeline-service.webapp.https.address": "${yarn.timeline-service.hostname}:8190",
        "mapreduce.task.timeout": "600000",
        "yarn.sharedcache.client-server.thread-count": "50",
        "hadoop.security.groups.shell.command.timeout": "0s",
        "hadoop.security.crypto.cipher.suite": "AES/CTR/NoPadding",
        "yarn.nodemanager.elastic-memory-control.oom-handler": "org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.DefaultOOMHandler",
        "yarn.resourcemanager.connect.max-wait.ms": "900000",
        "fs.defaultFS": "file:///",
        "yarn.minicluster.use-rpc": "false",
        "io.compression.codec.bzip2.library": "system-native",
        "yarn.webapp.filter-invalid-xml-chars": "false",
        "yarn.nodemanager.runtime.linux.runc.layer-mounts-interval-secs": "600",
        "fs.s3a.select.input.csv.record.delimiter": "\\n",
        "fs.s3a.change.detection.source": "etag",
        "ipc.[port_number].backoff.enable": "false",
        "yarn.nodemanager.distributed-scheduling.enabled": "false",
        "mapreduce.shuffle.connection-keep-alive.timeout": "5",
        "yarn.resourcemanager.webapp.https.address": "${yarn.resourcemanager.hostname}:8090",
        "yarn.webapp.enable-rest-app-submissions": "true",
        "fs.AbstractFileSystem.s3a.impl": "org.apache.hadoop.fs.s3a.S3A",
        "mapreduce.task.combine.progress.records": "10000",
        "yarn.resourcemanager.epoch.range": "0",
        "yarn.resourcemanager.am.max-attempts": "2",
        "yarn.nodemanager.runtime.linux.runc.image-toplevel-dir": "/runc-root",
        "yarn.nodemanager.linux-container-executor.cgroups.hierarchy": "/hadoop-yarn",
        "fs.AbstractFileSystem.wasbs.impl": "org.apache.hadoop.fs.azure.Wasbs",
        "yarn.timeline-service.entity-group-fs-store.cache-store-class": "org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore",
        "yarn.nodemanager.runtime.linux.runc.allowed-container-networks": "host,none,bridge",
        "fs.ftp.transfer.mode": "BLOCK_TRANSFER_MODE",
        "ipc.[port_number].decay-scheduler.decay-factor": "0.5",
        "fs.har.impl.disable.cache": "true",
        "yarn.webapp.ui2.enable": "false",
        "mapreduce.jobhistory.address": "0.0.0.0:10020",
        "yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs": "*********(redacted)",
        "yarn.is.minicluster": "false",
        "yarn.nodemanager.address": "${yarn.nodemanager.hostname}:0",
        "fs.abfss.impl": "org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem",
        "ipc.server.log.slow.rpc": "false",
        "ipc.server.reuseaddr": "true",
        "yarn.router.webapp.https.address": "0.0.0.0:8091",
        "yarn.nodemanager.webapp.cross-origin.enabled": "false",
        "fs.wasb.impl": "org.apache.hadoop.fs.azure.NativeAzureFileSystem",
        "fs.AbstractFileSystem.abfs.impl": "org.apache.hadoop.fs.azurebfs.Abfs",
        "hadoop.security.credential.clear-text-fallback": "true",
        "yarn.timeline-service.writer.async.queue.capacity": "100",
        "yarn.resourcemanager.fs.state-store.num-retries": "0",
        "yarn.resourcemanager.nodemanager-connect-retries": "10",
        "fs.ftp.timeout": "0",
        "yarn.resourcemanager.node-labels.provider.fetch-interval-ms": "1800000",
        "yarn.resourcemanager.auto-update.containers": "false",
        "yarn.app.mapreduce.am.job.committer.cancel-timeout": "60000",
        "yarn.scheduler.configuration.zk-store.parent-path": "/confstore",
        "yarn.nodemanager.default-container-executor.log-dirs.permissions": "710",
        "yarn.app.attempt.diagnostics.limit.kc": "64",
        "fs.viewfs.overload.scheme.target.swebhdfs.impl": "org.apache.hadoop.hdfs.web.SWebHdfsFileSystem",
        "yarn.client.failover-no-ha-proxy-provider": "org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider",
        "fs.s3a.change.detection.mode": "server",
        "ftp.bytes-per-checksum": "512",
        "yarn.nodemanager.resource.memory-mb": "-1",
        "yarn.timeline-service.writer.flush-interval-seconds": "60",
        "fs.s3a.fast.upload.active.blocks": "4",
        "yarn.resourcemanager.submission-preprocessor.enabled": "false",
        "yarn.nodemanager.collector-service.thread-count": "5",
        "ipc.[port_number].scheduler.impl": "org.apache.hadoop.ipc.DefaultRpcScheduler",
        "fs.azure.secure.mode": "false",
        "mapreduce.jobhistory.joblist.cache.size": "20000",
        "fs.ftp.host": "0.0.0.0",
        "yarn.nodemanager.log-aggregation.num-log-files-per-app": "30",
        "hadoop.security.kms.client.encrypted.key.cache.low-watermark": "0.3f",
        "fs.s3a.committer.magic.enabled": "true",
        "yarn.timeline-service.client.max-retries": "30",
        "dfs.ha.fencing.ssh.connect-timeout": "30000",
        "yarn.log-aggregation-enable": "false",
        "yarn.system-metrics-publisher.enabled": "false",
        "mapreduce.reduce.markreset.buffer.percent": "0.0",
        "fs.AbstractFileSystem.viewfs.impl": "org.apache.hadoop.fs.viewfs.ViewFs",
        "yarn.resourcemanager.nodemanagers.heartbeat-interval-speedup-factor": "1.0",
        "ha.failover-controller.new-active.rpc-timeout.ms": "60000",
        "yarn.nodemanager.container-localizer.java.opts": "-Xmx256m",
        "yarn.app.mapreduce.am.job.committer.commit-window": "10000",
        "hadoop.tags.system": "YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL",
        "hadoop.caller.context.signature.max.size": "40",
        "yarn.scheduler.configuration.store.max-logs": "1000",
        "yarn.nodemanager.node-attributes.provider.fetch-interval-ms": "600000",
        "hadoop.http.cross-origin.enabled": "false",
        "hadoop.zk.acl": "world:anyone:rwcda",
        "mapreduce.task.io.sort.factor": "10",
        "yarn.nodemanager.amrmproxy.client.thread-count": "25",
        "mapreduce.jobhistory.datestring.cache.size": "200000",
        "mapreduce.job.acl-modify-job": " ",
        "yarn.nodemanager.windows-container.memory-limit.enabled": "false",
        "yarn.timeline-service.webapp.address": "${yarn.timeline-service.hostname}:8188",
        "yarn.nodemanager.container-manager.thread-count": "20",
        "yarn.minicluster.fixed.ports": "false",
        "yarn.cluster.max-application-priority": "0",
        "yarn.timeline-service.ttl-enable": "true",
        "mapreduce.jobhistory.recovery.store.fs.uri": "${hadoop.tmp.dir}/mapred/history/recoverystore",
        "ipc.[port_number].decay-scheduler.backoff.responsetime.enable": "false",
        "yarn.client.load.resource-types.from-server": "false",
        "ha.zookeeper.session-timeout.ms": "10000",
        "ipc.[port_number].decay-scheduler.metrics.top.user.count": "10",
        "tfile.io.chunk.size": "1048576",
        "fs.s3a.s3guard.ddb.table.capacity.write": "0",
        "yarn.dispatcher.print-events-info.threshold": "5000",
        "mapreduce.job.speculative.slowtaskthreshold": "1.0",
        "io.serializations": "org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization",
        "hadoop.security.kms.client.failover.sleep.max.millis": "2000",
        "hadoop.security.group.mapping.ldap.directory.search.timeout": "10000",
        "fs.swift.impl": "org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem",
        "yarn.nodemanager.local-cache.max-files-per-directory": "8192",
        "yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.num-manifests-to-cache": "10",
        "mapreduce.map.sort.spill.percent": "0.80",
        "yarn.timeline-service.entity-group-fs-store.scan-interval-seconds": "60",
        "fs.s3a.select.enabled": "true",
        "mapreduce.ifile.readahead": "true",
        "yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms": "300000",
        "yarn.timeline-service.hbase.coprocessor.jar.hdfs.location": "/hbase/coprocessor/hadoop-yarn-server-timelineservice.jar",
        "hadoop.security.kms.client.encrypted.key.cache.num.refill.threads": "2",
        "yarn.resourcemanager.scheduler.class": "org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler",
        "hadoop.http.sni.host.check.enabled": "false",
        "fs.client.resolve.topology.enabled": "false",
        "yarn.nodemanager.runtime.linux.allowed-runtimes": "default",
        "io.skip.checksum.errors": "false",
        "yarn.timeline-service.client.best-effort": "false",
        "yarn.node-attribute.fs-store.impl.class": "org.apache.hadoop.yarn.server.resourcemanager.nodelabels.FileSystemNodeAttributeStore",
        "fs.s3a.retry.interval": "500ms",
        "yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled": "*********(redacted)",
        "hadoop.security.group.mapping.ldap.posix.attr.uid.name": "uidNumber",
        "fs.AbstractFileSystem.swebhdfs.impl": "org.apache.hadoop.fs.SWebHdfs",
        "yarn.nodemanager.elastic-memory-control.timeout-sec": "5",
        "yarn.timeline-service.reader.webapp.address": "${yarn.timeline-service.webapp.address}",
        "yarn.resourcemanager.placement-constraints.algorithm.pool-size": "1",
        "yarn.app.mapreduce.am.command-opts": "-Xmx1024m",
        "fs.s3a.metadatastore.fail.on.write.error": "true",
        "mapreduce.cluster.local.dir": "${hadoop.tmp.dir}/mapred/local",
        "io.mapfile.bloom.error.rate": "0.005",
        "yarn.sharedcache.store.class": "org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore",
        "ha.failover-controller.graceful-fence.rpc-timeout.ms": "5000",
        "ftp.replication": "3",
        "fs.getspaceused.jitterMillis": "60000",
        "hadoop.security.uid.cache.secs": "14400",
        "mapreduce.job.maxtaskfailures.per.tracker": "3",
        "fs.s3a.metadatastore.impl": "org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore",
        "yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts": "3",
        "yarn.timeline-service.webapp.xfs-filter.xframe-options": "SAMEORIGIN",
        "fs.s3a.connection.timeout": "200000",
        "yarn.app.mapreduce.am.webapp.https.enabled": "false",
        "mapreduce.job.max.split.locations": "15",
        "yarn.resourcemanager.nm-container-queuing.max-queue-length": "15",
        "yarn.resourcemanager.delegation-token.always-cancel": "*********(redacted)",
        "hadoop.registry.zk.session.timeout.ms": "60000",
        "yarn.federation.cache-ttl.secs": "300",
        "mapreduce.jvm.system-properties-to-log": "os.name,os.version,java.home,java.runtime.version,java.vendor,java.version,java.vm.name,java.class.path,java.io.tmpdir,user.dir,user.name",
        "yarn.resourcemanager.opportunistic-container-allocation.nodes-used": "10",
        "yarn.minicluster.yarn.nodemanager.resource.memory-mb": "4096",
        "yarn.resourcemanager.admin.client.thread-count": "1",
        "yarn.dispatcher.drain-events.timeout": "300000",
        "yarn.timeline-service.entity-group-fs-store.active-dir": "/tmp/entity-file-history/active",
        "mapreduce.shuffle.transfer.buffer.size": "131072",
        "yarn.timeline-service.client.retry-interval-ms": "1000",
        "yarn.timeline-service.flowname.max-size": "0",
        "yarn.http.policy": "HTTP_ONLY",
        "fs.s3a.socket.send.buffer": "8192",
        "fs.AbstractFileSystem.abfss.impl": "org.apache.hadoop.fs.azurebfs.Abfss",
        "yarn.sharedcache.uploader.server.address": "0.0.0.0:8046",
        "yarn.resourcemanager.delegation-token.max-conf-size-bytes": "*********(redacted)",
        "hadoop.http.authentication.token.validity": "*********(redacted)",
        "mapreduce.shuffle.max.connections": "0",
        "mapreduce.job.emit-timeline-data": "false",
        "yarn.nodemanager.resource.system-reserved-memory-mb": "-1",
        "hadoop.kerberos.min.seconds.before.relogin": "60",
        "mapreduce.jobhistory.move.thread-count": "3",
        "ipc.[port_number].decay-scheduler.backoff.responsetime.thresholds": "10s,20s,30s,40s",
        "fs.s3a.buffer.dir": "${hadoop.tmp.dir}/s3a",
        "hadoop.ssl.enabled.protocols": "TLSv1.2",
        "mapreduce.jobhistory.admin.address": "0.0.0.0:10033",
        "yarn.log-aggregation-status.time-out.ms": "600000",
        "fs.s3a.accesspoint.required": "false",
        "yarn.nodemanager.health-checker.interval-ms": "600000",
        "yarn.router.clientrm.interceptor-class.pipeline": "org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor",
        "yarn.nodemanager.runtime.linux.sandbox-mode.local-dirs.permissions": "read",
        "yarn.resourcemanager.activities-manager.app-activities.max-queue-length": "100",
        "yarn.nodemanager.pmem-check-enabled": "true",
        "yarn.federation.enabled": "false",
        "yarn.resourcemanager.nm-container-queuing.load-comparator": "QUEUE_LENGTH",
        "mapreduce.job.complete.cancel.delegation.tokens": "*********(redacted)",
        "yarn.nodemanager.amrmproxy.ha.enable": "false",
        "fs.AbstractFileSystem.gs.impl": "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS",
        "mapreduce.shuffle.port": "13562",
        "yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory": "10",
        "yarn.resourcemanager.zk-appid-node.split-index": "0",
        "ftp.blocksize": "67108864",
        "yarn.router.rmadmin.interceptor-class.pipeline": "org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor",
        "yarn.nodemanager.log-container-debug-info.enabled": "true",
        "yarn.resourcemanager.application-https.policy": "NONE",
        "yarn.client.max-cached-nodemanagers-proxies": "0",
        "yarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms": "20",
        "yarn.nodemanager.delete.debug-delay-sec": "0",
        "yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage": "90.0",
        "mapreduce.app-submission.cross-platform": "false",
        "yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms": "10000",
        "yarn.nodemanager.container-retry-minimum-interval-ms": "1000",
        "hadoop.security.groups.cache.secs": "300",
        "yarn.workflow-id.tag-prefix": "workflowid:",
        "fs.azure.local.sas.key.mode": "false",
        "ipc.maximum.data.length": "134217728",
        "yarn.router.pipeline.cache-max-size": "25",
        "fs.s3a.endpoint": "s3.amazonaws.com",
        "mapreduce.shuffle.max.threads": "0",
        "yarn.resourcemanager.resource-tracker.nm.ip-hostname-check": "false",
        "hadoop.security.authorization": "false",
        "fs.s3a.paging.maximum": "5000",
        "nfs.exports.allowed.hosts": "* rw",
        "mapreduce.jobhistory.http.policy": "HTTP_ONLY",
        "yarn.sharedcache.store.in-memory.check-period-mins": "720",
        "hadoop.security.group.mapping.ldap.ssl": "false",
        "yarn.scheduler.configuration.leveldb-store.compaction-interval-secs": "86400",
        "yarn.timeline-service.writer.class": "org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineWriterImpl",
        "ha.zookeeper.parent-znode": "/hadoop-ha",
        "yarn.resourcemanager.submission-preprocessor.file-refresh-interval-ms": "60000",
        "hadoop.security.group.mapping.ldap.search.filter.group": "(objectClass=group)",
        "yarn.resourcemanager.placement-constraints.scheduler.pool-size": "1",
        "yarn.resourcemanager.activities-manager.cleanup-interval-ms": "5000",
        "yarn.admin.acl": "*",
        "yarn.sharedcache.admin.thread-count": "1",
        "mapreduce.task.local-fs.write-limit.bytes": "-1",
        "fs.adl.oauth2.access.token.provider.type": "*********(redacted)",
        "yarn.nodemanager.resource-plugins.gpu.docker-plugin": "nvidia-docker-v1",
        "fs.s3a.downgrade.syncable.exceptions": "true",
        "yarn.client.application-client-protocol.poll-interval-ms": "200",
        "yarn.nodemanager.log-aggregation.policy.class": "org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AllContainerLogAggregationPolicy",
        "mapreduce.reduce.shuffle.merge.percent": "0.66",
        "yarn.nodemanager.resourcemanager.minimum.version": "NONE",
        "mapreduce.job.speculative.speculative-cap-running-tasks": "0.1",
        "ipc.[port_number].identity-provider.impl": "org.apache.hadoop.ipc.UserIdentityProvider",
        "yarn.nodemanager.recovery.supervised": "false",
        "mapreduce.reduce.skip.maxgroups": "0",
        "yarn.resourcemanager.ha.automatic-failover.enabled": "true",
        "yarn.nodemanager.container-log-monitor.total-size-limit-bytes": "10000000000",
        "mapreduce.reduce.shuffle.connect.timeout": "180000",
        "yarn.nodemanager.health-checker.scripts": "script",
        "yarn.resourcemanager.address": "${yarn.resourcemanager.hostname}:8032",
        "ipc.client.ping": "true",
        "mapreduce.shuffle.ssl.file.buffer.size": "65536",
        "yarn.resourcemanager.ha.automatic-failover.embedded": "true",
        "fs.s3a.s3guard.consistency.retry.interval": "2s",
        "yarn.resourcemanager.nm-container-queuing.queue-limit-stdev": "1.0f",
        "mapreduce.job.end-notification.max.attempts": "5",
        "yarn.nodemanager.keytab": "/etc/krb5.keytab",
        "mapreduce.jobhistory.keytab": "/etc/security/keytab/jhs.service.keytab",
        "fs.s3a.threads.max": "64",
        "yarn.nodemanager.runtime.linux.docker.image-update": "false",
        "mapreduce.reduce.shuffle.input.buffer.percent": "0.70",
        "fs.viewfs.overload.scheme.target.abfss.impl": "org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem",
        "yarn.dispatcher.cpu-monitor.samples-per-min": "60",
        "hadoop.security.token.service.use_ip": "*********(redacted)",
        "yarn.nodemanager.runtime.linux.docker.allowed-container-networks": "host,none,bridge",
        "yarn.nodemanager.node-labels.resync-interval-ms": "120000",
        "mapreduce.job.end-notification.max.retry.interval": "5000",
        "yarn.nodemanager.containers-launcher.class": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher",
        "fs.s3a.multipart.purge": "false",
        "yarn.scheduler.configuration.store.class": "file",
        "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.DefaultCodec",
        "yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled": "false",
        "ipc.client.bind.wildcard.addr": "false",
        "yarn.resourcemanager.webapp.rest-csrf.enabled": "false",
        "ha.health-monitor.connect-retry-interval.ms": "1000",
        "hadoop.tmp.dir": "/tmp/hadoop-${user.name}",
        "mapreduce.job.maps": "2",
        "mapreduce.jobhistory.webapp.rest-csrf.custom-header": "X-XSRF-Header",
        "yarn.log-aggregation.retain-check-interval-seconds": "-1",
        "yarn.resourcemanager.resource-tracker.client.thread-count": "50",
        "yarn.resourcemanager.ha.automatic-failover.zk-base-path": "/yarn-leader-election",
        "fs.AbstractFileSystem.wasb.impl": "org.apache.hadoop.fs.azure.Wasb",
        "mapreduce.client.submit.file.replication": "10",
        "mapreduce.jobhistory.minicluster.fixed.ports": "false",
        "fs.s3a.multipart.threshold": "128M",
        "yarn.resourcemanager.webapp.xfs-filter.xframe-options": "SAMEORIGIN",
        "yarn.rm.system-metrics-publisher.emit-container-events": "false",
        "yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size": "10000",
        "io.seqfile.local.dir": "${hadoop.tmp.dir}/io/local",
        "fs.s3a.s3guard.ddb.throttle.retry.interval": "100ms",
        "mapreduce.jobhistory.done-dir": "${yarn.app.mapreduce.am.staging-dir}/history/done",
        "ipc.server.purge.interval": "15",
        "ipc.client.idlethreshold": "4000",
        "yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage": "false",
        "mapreduce.reduce.input.buffer.percent": "0.0",
        "yarn.nodemanager.runtime.linux.docker.userremapping-gid-threshold": "1",
        "yarn.nodemanager.webapp.rest-csrf.enabled": "false",
        "yarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size": "10",
        "fs.ftp.host.port": "21",
        "ipc.ping.interval": "60000",
        "yarn.resourcemanager.admin.address": "${yarn.resourcemanager.hostname}:8033",
        "file.client-write-packet-size": "65536",
        "ipc.client.kill.max": "10",
        "mapreduce.reduce.speculative": "true",
        "ipc.client.connection.maxidletime": "10000",
        "mapreduce.task.io.sort.mb": "100",
        "yarn.nodemanager.localizer.client.thread-count": "5",
        "io.erasurecode.codec.rs.rawcoders": "rs_native,rs_java",
        "io.erasurecode.codec.rs-legacy.rawcoders": "rs-legacy_java",
        "yarn.nodemanager.localizer.cache.cleanup.interval-ms": "600000",
        "yarn.nodemanager.process-kill-wait.ms": "5000",
        "mapreduce.job.hdfs-servers": "${fs.defaultFS}",
        "fs.s3a.multiobjectdelete.enable": "true",
        "fs.viewfs.overload.scheme.target.wasb.impl": "org.apache.hadoop.fs.azure.NativeAzureFileSystem",
        "hadoop.security.group.mapping.ldap.search.attr.member": "member",
        "hadoop.security.random.device.file.path": "/dev/urandom",
        "hadoop.security.sensitive-config-keys": "*********(redacted)",
        "hadoop.rpc.socket.factory.class.default": "org.apache.hadoop.net.StandardSocketFactory",
        "yarn.intermediate-data-encryption.enable": "false",
        "hadoop.security.key.default.bitlength": "128",
        "mapreduce.job.reducer.unconditional-preempt.delay.sec": "300",
        "yarn.nodemanager.disk-health-checker.interval-ms": "120000",
        "yarn.nodemanager.log.deletion-threads-count": "4",
        "fs.s3a.committer.abort.pending.uploads": "true",
        "yarn.webapp.filter-entity-list-by-user": "false",
        "yarn.resourcemanager.activities-manager.app-activities.ttl-ms": "600000",
        "yarn.sharedcache.admin.address": "0.0.0.0:8047",
        "yarn.resourcemanager.placement-constraints.algorithm.iterator": "SERIAL",
        "hadoop.security.crypto.codec.classes.aes.ctr.nopadding": "org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec",
        "mapreduce.job.cache.limit.max-resources-mb": "0",
        "fs.s3a.connection.ssl.enabled": "true",
        "yarn.app.mapreduce.am.webapp.https.client.auth": "false",
        "hadoop.workaround.non.threadsafe.getpwuid": "true",
        "fs.df.interval": "60000",
        "ipc.[port_number].decay-scheduler.thresholds": "13,25,50",
        "yarn.sharedcache.cleaner.resource-sleep-ms": "0",
        "yarn.nodemanager.disk-health-checker.min-healthy-disks": "0.25",
        "hadoop.shell.missing.defaultFs.warning": "false",
        "io.file.buffer.size": "65536",
        "fs.s3a.s3guard.ddb.max.retries": "9",
        "fs.viewfs.overload.scheme.target.file.impl": "org.apache.hadoop.fs.LocalFileSystem",
        "yarn.resourcemanager.connect.retry-interval.ms": "30000",
        "yarn.nodemanager.container.stderr.pattern": "{*stderr*,*STDERR*}",
        "yarn.scheduler.minimum-allocation-mb": "1024",
        "hadoop.http.cross-origin.max-age": "1800",
        "fs.s3a.connection.establish.timeout": "5000",
        "yarn.federation.state-store.class": "org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore",
        "mapreduce.reduce.log.level": "INFO",
        "yarn.resourcemanager.placement-constraints.retry-attempts": "3",
        "yarn.nodemanager.vmem-pmem-ratio": "2.1",
        "hadoop.rpc.protection": "authentication",
        "yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size": "10",
        "yarn.app.mapreduce.am.staging-dir": "/tmp/hadoop-yarn/staging",
        "mapreduce.reduce.shuffle.read.timeout": "180000",
        "io.erasurecode.codec.xor.rawcoders": "xor_native,xor_java",
        "fs.s3a.s3guard.consistency.retry.limit": "7",
        "mapreduce.job.running.map.limit": "0",
        "yarn.minicluster.control-resource-monitoring": "false",
        "hadoop.ssl.require.client.cert": "false",
        "hadoop.kerberos.kinit.command": "kinit",
        "adl.http.timeout": "-1",
        "hadoop.security.dns.log-slow-lookups.threshold.ms": "1000",
        "mapreduce.job.ubertask.enable": "false",
        "hadoop.caller.context.enabled": "false",
        "hadoop.security.group.mapping.ldap.num.attempts": "3",
        "ha.health-monitor.rpc-timeout.ms": "45000",
        "yarn.nodemanager.remote-app-log-dir": "/tmp/logs",
        "hadoop.zk.timeout-ms": "10000",
        "fs.s3a.s3guard.cli.prune.age": "86400000",
        "yarn.nodemanager.resource.pcores-vcores-multiplier": "1.0",
        "yarn.nodemanager.runtime.linux.sandbox-mode": "disabled",
        "fs.viewfs.overload.scheme.target.webhdfs.impl": "org.apache.hadoop.hdfs.web.WebHdfsFileSystem",
        "fs.s3a.committer.threads": "8",
        "yarn.nodemanager.delete.thread-count": "4",
        "mapreduce.job.finish-when-all-reducers-done": "true",
        "hadoop.registry.jaas.context": "Client",
        "yarn.timeline-service.leveldb-timeline-store.path": "${hadoop.tmp.dir}/yarn/timeline",
        "io.map.index.interval": "128",
        "mapreduce.jobhistory.webapp.rest-csrf.enabled": "false",
        "fs.s3a.change.detection.version.required": "true",
        "yarn.nodemanager.localizer.fetch.thread-count": "4",
        "yarn.resourcemanager.scheduler.client.thread-count": "50",
        "hadoop.ssl.hostname.verifier": "DEFAULT",
        "yarn.timeline-service.leveldb-state-store.path": "${hadoop.tmp.dir}/yarn/timeline",
        "hadoop.zk.retry-interval-ms": "1000",
        "hadoop.security.crypto.buffer.size": "8192",
        "yarn.nodemanager.node-labels.provider.fetch-interval-ms": "600000",
        "mapreduce.jobhistory.recovery.store.leveldb.path": "${hadoop.tmp.dir}/mapred/history/recoverystore",
        "yarn.client.failover-retries-on-socket-timeouts": "0",
        "fs.s3a.ssl.channel.mode": "default_jsse",
        "yarn.nodemanager.resource.memory.enabled": "false",
        "fs.azure.authorization.caching.enable": "true",
        "hadoop.security.instrumentation.requires.admin": "false",
        "yarn.resourcemanager.nm-container-queuing.max-queue-wait-time-ms": "100",
        "fs.abfs.impl": "org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem",
        "mapreduce.job.counters.max": "120",
        "yarn.timeline-service.store-class": "org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore",
        "mapreduce.jobhistory.move.interval-ms": "180000",
        "mapreduce.job.classloader": "false",
        "mapreduce.task.profile.map.params": "${mapreduce.task.profile.params}",
        "ipc.client.connect.timeout": "20000",
        "hadoop.security.auth_to_local.mechanism": "hadoop",
        "yarn.resourcemanager.reservation-system.planfollower.time-step": "1000",
        "yarn.resourcemanager.activities-manager.scheduler-activities.ttl-ms": "600000",
        "yarn.nodemanager.runtime.linux.docker.enable-userremapping.allowed": "true",
        "yarn.webapp.api-service.enable": "false",
        "yarn.nodemanager.container.stderr.tail.bytes": "4096",
        "yarn.nodemanager.disk-health-checker.disk-free-space-threshold.enabled": "true",
        "hadoop.security.group.mapping.ldap.read.timeout.ms": "60000",
        "hadoop.security.groups.cache.warn.after.ms": "5000",
        "file.bytes-per-checksum": "512",
        "mapreduce.outputcommitter.factory.scheme.s3a": "org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory",
        "yarn.timeline-service.app-collector.linger-period.ms": "60000",
        "yarn.nm.liveness-monitor.expiry-interval-ms": "600000",
        "yarn.nodemanager.recovery.enabled": "false",
        "mapreduce.job.end-notification.retry.interval": "1000",
        "fs.du.interval": "600000",
        "fs.ftp.impl": "org.apache.hadoop.fs.ftp.FTPFileSystem",
        "hadoop.security.groups.cache.background.reload": "false",
        "yarn.nodemanager.container-monitor.enabled": "true",
        "yarn.nodemanager.elastic-memory-control.enabled": "false",
        "net.topology.script.number.args": "100",
        "mapreduce.task.merge.progress.records": "10000",
        "yarn.nodemanager.container-executor.exit-code-file.timeout-ms": "2000",
        "mapreduce.fileoutputcommitter.algorithm.version": "1",
        "yarn.sharedcache.root-dir": "/sharedcache",
        "fs.s3a.retry.throttle.limit": "20",
        "hadoop.http.authentication.type": "simple",
        "fs.viewfs.overload.scheme.target.oss.impl": "org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem",
        "mapreduce.job.cache.limit.max-resources": "0",
        "mapreduce.task.userlog.limit.kb": "0",
        "ipc.[port_number].weighted-cost.handler": "1",
        "yarn.resourcemanager.scheduler.monitor.enable": "false",
        "ipc.client.connect.max.retries": "10",
        "hadoop.registry.zk.retry.times": "5",
        "yarn.nodemanager.localizer.address": "${yarn.nodemanager.hostname}:8040",
        "yarn.timeline-service.keytab": "/etc/krb5.keytab",
        "mapreduce.reduce.shuffle.fetch.retry.timeout-ms": "30000",
        "yarn.resourcemanager.rm.container-allocation.expiry-interval-ms": "600000",
        "yarn.resourcemanager.work-preserving-recovery.enabled": "true",
        "mapreduce.map.skip.maxrecords": "0",
        "yarn.nodemanager.resource-monitor.interval-ms": "3000",
        "yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices": "auto",
        "mapreduce.job.sharedcache.mode": "disabled",
        "mapreduce.map.cpu.vcores": "1",
        "mapreduce.job.reducer.preempt.delay.sec": "0",
        "hadoop.util.hash.type": "murmur",
        "yarn.nodemanager.webapp.rest-csrf.custom-header": "X-XSRF-Header",
        "mapreduce.shuffle.listen.queue.size": "128",
        "yarn.scheduler.configuration.mutation.acl-policy.class": "org.apache.hadoop.yarn.server.resourcemanager.scheduler.DefaultConfigurationMutationACLPolicy",
        "yarn.log-aggregation.file-formats": "TFile",
        "yarn.timeline-service.client.fd-retain-secs": "300",
        "fs.s3a.select.output.csv.field.delimiter": ",",
        "yarn.nodemanager.health-checker.timeout-ms": "1200000",
        "hadoop.user.group.static.mapping.overrides": "dr.who=;",
        "fs.azure.sas.expiry.period": "90d",
        "fs.s3a.select.output.csv.record.delimiter": "\\n",
        "mapreduce.jobhistory.recovery.store.class": "org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService",
        "fs.viewfs.overload.scheme.target.https.impl": "org.apache.hadoop.fs.http.HttpsFileSystem",
        "fs.s3a.s3guard.ddb.table.sse.enabled": "false",
        "yarn.resourcemanager.fail-fast": "${yarn.fail-fast}",
        "yarn.resourcemanager.proxy-user-privileges.enabled": "false",
        "yarn.router.webapp.interceptor-class.pipeline": "org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST",
        "yarn.nodemanager.resource.memory.cgroups.soft-limit-percentage": "90.0",
        "yarn.nodemanager.disk-validator": "basic",
        "yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms": "1000",
        "fs.AbstractFileSystem.file.impl": "org.apache.hadoop.fs.local.LocalFs",
        "yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds": "-1",
        "mapreduce.jobhistory.cleaner.interval-ms": "86400000",
        "yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs": "*********(redacted)",
        "hadoop.ssl.server.conf": "ssl-server.xml",
        "fs.s3a.retry.throttle.interval": "100ms",
        "mapreduce.client.completion.pollinterval": "5000",
        "hadoop.ssl.keystores.factory.class": "org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory",
        "yarn.timeline-service.entity-group-fs-store.done-dir": "/tmp/entity-file-history/done/",
        "yarn.resourcemanager.fs.state-store.uri": "${hadoop.tmp.dir}/yarn/system/rmstore",
        "mapreduce.jobhistory.always-scan-user-dir": "false",
        "yarn.app.mapreduce.client.job.max-retries": "3",
        "fs.viewfs.overload.scheme.target.ftp.impl": "org.apache.hadoop.fs.ftp.FTPFileSystem",
        "mapreduce.reduce.shuffle.retry-delay.max.ms": "60000",
        "hadoop.security.group.mapping.ldap.connection.timeout.ms": "60000",
        "mapreduce.task.profile.params": "-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s",
        "yarn.app.mapreduce.shuffle.log.backups": "0",
        "yarn.nodemanager.container-diagnostics-maximum-size": "10000",
        "hadoop.registry.zk.retry.interval.ms": "1000",
        "hadoop.registry.zk.quorum": "localhost:2181",
        "yarn.nodemanager.runtime.linux.runc.allowed-container-runtimes": "runc",
        "mapreduce.output.fileoutputformat.compress": "false",
        "fs.s3a.assumed.role.session.duration": "30m",
        "hadoop.security.group.mapping.ldap.conversion.rule": "none",
        "seq.io.sort.factor": "100",
        "fs.viewfs.overload.scheme.target.ofs.impl": "org.apache.hadoop.fs.ozone.RootedOzoneFileSystem",
        "yarn.sharedcache.cleaner.initial-delay-mins": "10",
        "yarn.app.mapreduce.am.resource.cpu-vcores": "1",
        "yarn.timeline-service.enabled": "false",
        "yarn.nodemanager.runtime.linux.docker.capabilities": "CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE",
        "yarn.acl.enable": "false",
        "hadoop.prometheus.endpoint.enabled": "false",
        "hadoop.security.group.mapping.ldap.num.attempts.before.failover": "3",
        "mapreduce.task.profile": "false",
        "fs.s3a.metadatastore.metadata.ttl": "15m",
        "yarn.nodemanager.opportunistic-containers-use-pause-for-preemption": "false",
        "yarn.nodemanager.resource.percentage-physical-cpu-limit": "100",
        "yarn.resourcemanager.opportunistic.max.container-allocation.per.am.heartbeat": "-1",
        "ipc.[port_number].cost-provider.impl": "org.apache.hadoop.ipc.DefaultCostProvider",
        "yarn.nodemanager.resource.memory.cgroups.swappiness": "0",
        "yarn.timeline-service.address": "${yarn.timeline-service.hostname}:10200",
        "ha.failover-controller.graceful-fence.connection.retries": "1",
        "yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user": "nobody",
        "yarn.timeline-service.reader.class": "org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineReaderImpl",
        "yarn.resourcemanager.configuration.provider-class": "org.apache.hadoop.yarn.LocalConfigurationProvider",
        "yarn.nodemanager.runtime.linux.docker.userremapping-uid-threshold": "1",
        "yarn.resourcemanager.configuration.file-system-based-store": "/yarn/conf",
        "mapreduce.job.cache.limit.max-single-resource-mb": "0",
        "yarn.nodemanager.runtime.linux.docker.stop.grace-period": "10",
        "yarn.resourcemanager.resource-profiles.source-file": "resource-profiles.json",
        "mapreduce.job.dfs.storage.capacity.kill-limit-exceed": "false",
        "mapreduce.jobhistory.client.thread-count": "10",
        "tfile.fs.input.buffer.size": "262144",
        "mapreduce.client.progressmonitor.pollinterval": "1000",
        "yarn.nodemanager.log-dirs": "${yarn.log.dir}/userlogs",
        "fs.automatic.close": "true",
        "yarn.resourcemanager.delegation-token-renewer.thread-retry-interval": "*********(redacted)",
        "fs.s3a.select.input.csv.quote.character": "\"",
        "yarn.nodemanager.hostname": "0.0.0.0",
        "yarn.nodemanager.runtime.linux.runc.manifest-to-resources-plugin": "org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.HdfsManifestToResourcesPlugin",
        "yarn.nodemanager.remote-app-log-dir-include-older": "true",
        "ftp.stream-buffer-size": "4096",
        "yarn.fail-fast": "false",
        "yarn.nodemanager.runtime.linux.runc.layer-mounts-to-keep": "100",
        "yarn.timeline-service.app-aggregation-interval-secs": "15",
        "hadoop.security.group.mapping.ldap.search.filter.user": "(&(objectClass=user)(sAMAccountName={0}))",
        "ipc.[port_number].weighted-cost.lockshared": "10",
        "yarn.nodemanager.container-localizer.log.level": "INFO",
        "mapreduce.job.ubertask.maxmaps": "9",
        "fs.s3a.threads.keepalivetime": "60",
        "mapreduce.jobhistory.webapp.rest-csrf.methods-to-ignore": "GET,OPTIONS,HEAD",
        "mapreduce.task.files.preserve.failedtasks": "false",
        "yarn.app.mapreduce.client.job.retry-interval": "2000",
        "fs.s3a.select.output.csv.quote.escape.character": "\\\\",
        "yarn.timeline-service.client.drain-entities.timeout.ms": "2000",
        "yarn.nodemanager.resource-plugins.fpga.vendor-plugin.class": "org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin",
        "mapreduce.job.encrypted-intermediate-data.buffer.kb": "128",
        "fs.client.resolve.remote.symlinks": "true",
        "fs.s3a.executor.capacity": "16",
        "yarn.timeline-service.entity-group-fs-store.retain-seconds": "604800",
        "yarn.nodemanager.local-dirs": "${hadoop.tmp.dir}/nm-local-dir",
        "yarn.sharedcache.store.in-memory.staleness-period-mins": "10080",
        "fs.adl.impl": "org.apache.hadoop.fs.adl.AdlFileSystem",
        "yarn.resourcemanager.nodemanager.minimum.version": "NONE",
        "yarn.timeline-service.reader.webapp.https.address": "${yarn.timeline-service.webapp.https.address}",
        "yarn.resourcemanager.delegation.token.max-lifetime": "*********(redacted)",
        "hadoop.kerberos.keytab.login.autorenewal.enabled": "false",
        "yarn.resourcemanager.nodemanagers.heartbeat-interval-min-ms": "1000",
        "yarn.timeline-service.entity-group-fs-store.summary-store": "org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore",
        "mapreduce.reduce.cpu.vcores": "1",
        "yarn.nodemanager.webapp.https.address": "0.0.0.0:8044",
        "hadoop.http.cross-origin.allowed-origins": "*",
        "mapreduce.job.encrypted-intermediate-data": "false",
        "yarn.nodemanager.disk-health-checker.disk-utilization-threshold.enabled": "true",
        "yarn.resourcemanager.metrics.runtime.buckets": "60,300,1440",
        "yarn.timeline-service.generic-application-history.max-applications": "10000",
        "mapreduce.shuffle.connection-keep-alive.enable": "false",
        "yarn.node-labels.configuration-type": "centralized",
        "fs.s3a.path.style.access": "false",
        "yarn.nodemanager.aux-services.mapreduce_shuffle.class": "org.apache.hadoop.mapred.ShuffleHandler",
        "yarn.resourcemanager.application.max-tags": "10",
        "hadoop.domainname.resolver.impl": "org.apache.hadoop.net.DNSDomainNameResolver",
        "mapreduce.jobhistory.webapp.xfs-filter.xframe-options": "SAMEORIGIN",
        "yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled": "false",
        "net.topology.impl": "org.apache.hadoop.net.NetworkTopology",
        "io.map.index.skip": "0",
        "fs.ftp.data.connection.mode": "ACTIVE_LOCAL_DATA_CONNECTION_MODE",
        "yarn.nodemanager.log-aggregation.compression-type": "none",
        "yarn.timeline-service.version": "1.0f",
        "yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.batch-size": "1000",
        "fs.s3a.select.errors.include.sql": "false",
        "fs.s3a.connection.request.timeout": "0",
        "yarn.nodemanager.runtime.linux.docker.host-pid-namespace.allowed": "false",
        "yarn.nodemanager.recovery.dir": "${hadoop.tmp.dir}/yarn-nm-recovery",
        "fs.s3a.max.total.tasks": "32",
        "mapreduce.job.local-fs.single-disk-limit.check.kill-limit-exceed": "true",
        "fs.azure.buffer.dir": "${hadoop.tmp.dir}/abfs",
        "yarn.scheduler.maximum-allocation-vcores": "4",
        "hadoop.http.cross-origin.allowed-headers": "X-Requested-With,Content-Type,Accept,Origin",
        "yarn.ipc.rpc.class": "org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC",
        "mapreduce.reduce.maxattempts": "4",
        "hadoop.security.dns.log-slow-lookups.enabled": "false",
        "mapreduce.job.committer.setup.cleanup.needed": "true",
        "hadoop.security.secure.random.impl": "org.apache.hadoop.crypto.random.OpensslSecureRandom",
        "mapreduce.job.running.reduce.limit": "0",
        "ipc.maximum.response.length": "134217728",
        "yarn.resourcemanager.webapp.rest-csrf.methods-to-ignore": "GET,OPTIONS,HEAD",
        "mapreduce.job.token.tracking.ids.enabled": "*********(redacted)",
        "hadoop.caller.context.max.size": "128",
        "yarn.nodemanager.runtime.linux.docker.delayed-removal.allowed": "false",
        "hadoop.registry.system.acls": "sasl:yarn@, sasl:mapred@, sasl:hdfs@",
        "fs.s3a.fast.upload.buffer": "disk",
        "mapreduce.jobhistory.intermediate-done-dir": "${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate",
        "yarn.app.mapreduce.shuffle.log.separate": "true",
        "yarn.log-aggregation.debug.filesize": "104857600",
        "fs.s3a.readahead.range": "64K",
        "hadoop.http.authentication.simple.anonymous.allowed": "true",
        "fs.s3a.attempts.maximum": "20",
        "yarn.resourcemanager.delegation-token-renewer.thread-timeout": "*********(redacted)",
        "yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size": "10000",
        "yarn.nodemanager.aux-services.manifest.reload-ms": "0",
        "yarn.nodemanager.emit-container-events": "true",
        "yarn.resourcemanager.resource-profiles.enabled": "false",
        "yarn.timeline-service.hbase-schema.prefix": "prod.",
        "fs.azure.authorization": "false",
        "yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs": "20",
        "hadoop.security.group.mapping.ldap.search.group.hierarchy.levels": "0",
        "yarn.resourcemanager.fs.state-store.retry-interval-ms": "1000",
        "yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.hdfs-hash-file": "/runc-root/image-tag-to-hash",
        "mapreduce.job.speculative.retry-after-speculate": "15000",
        "hadoop.registry.zk.connection.timeout.ms": "15000",
        "yarn.resourcemanager.delegation-token-renewer.thread-count": "*********(redacted)",
        "mapreduce.map.log.level": "INFO",
        "ha.failover-controller.active-standby-elector.zk.op.retries": "3",
        "mapreduce.output.fileoutputformat.compress.type": "RECORD",
        "yarn.resourcemanager.leveldb-state-store.path": "${hadoop.tmp.dir}/yarn/system/rmstore",
        "yarn.timeline-service.webapp.rest-csrf.custom-header": "X-XSRF-Header",
        "mapreduce.ifile.readahead.bytes": "4194304",
        "yarn.sharedcache.app-checker.class": "org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker",
        "yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users": "true",
        "yarn.nodemanager.resource.detect-hardware-capabilities": "false",
        "mapreduce.cluster.acls.enabled": "false",
        "mapreduce.job.speculative.retry-after-no-speculate": "1000",
        "fs.viewfs.overload.scheme.target.abfs.impl": "org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem",
        "file.stream-buffer-size": "4096",
        "yarn.resourcemanager.application-timeouts.monitor.interval-ms": "3000",
        "mapreduce.map.output.compress.codec": "org.apache.hadoop.io.compress.DefaultCodec",
        "mapreduce.map.speculative": "true",
        "yarn.nodemanager.linux-container-executor.cgroups.mount": "false",
        "mapreduce.job.reduce.slowstart.completedmaps": "0.05",
        "yarn.timeline-service.client.internal-timers-ttl-secs": "420",
        "fs.s3a.select.output.csv.quote.character": "\"",
        "hadoop.http.logs.enabled": "true",
        "yarn.nodemanager.logaggregation.threadpool-size-max": "100",
        "fs.AbstractFileSystem.hdfs.impl": "org.apache.hadoop.fs.Hdfs",
        "yarn.nodemanager.disk-health-checker.enable": "true",
        "fs.s3a.select.output.csv.quote.fields": "always",
        "yarn.resourcemanager.delegation-token-renewer.thread-retry-max-attempts": "*********(redacted)",
        "yarn.app.mapreduce.am.container.log.backups": "0",
        "yarn.app.mapreduce.am.log.level": "INFO",
        "yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin": "org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.ImageTagToManifestPlugin",
        "io.bytes.per.checksum": "512",
        "yarn.timeline-service.http-authentication.type": "simple",
        "hadoop.security.group.mapping.ldap.search.attr.group.name": "cn",
        "yarn.nodemanager.resource-plugins.fpga.allowed-fpga-devices": "auto",
        "fs.s3a.block.size": "32M",
        "yarn.sharedcache.client-server.address": "0.0.0.0:8045",
        "yarn.resourcemanager.hostname": "0.0.0.0",
        "yarn.resourcemanager.delegation.key.update-interval": "86400000",
        "mapreduce.reduce.shuffle.fetch.retry.enabled": "${yarn.nodemanager.recovery.enabled}",
        "mapreduce.map.memory.mb": "-1",
        "mapreduce.task.skip.start.attempts": "2",
        "ipc.client.tcpnodelay": "true",
        "ipc.client.rpc-timeout.ms": "0",
        "yarn.nodemanager.webapp.rest-csrf.methods-to-ignore": "GET,OPTIONS,HEAD",
        "yarn.router.interceptor.user.threadpool-size": "5",
        "fs.AbstractFileSystem.har.impl": "org.apache.hadoop.fs.HarFs",
        "mapreduce.job.split.metainfo.maxsize": "10000000",
        "yarn.am.liveness-monitor.expiry-interval-ms": "600000",
        "yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-timeout-interval-secs": "360",
        "fs.s3a.socket.recv.buffer": "8192",
        "rpc.metrics.timeunit": "MILLISECONDS",
        "yarn.scheduler.configuration.fs.path": "file://${hadoop.tmp.dir}/yarn/system/schedconf",
        "mapreduce.reduce.memory.mb": "-1",
        "ipc.client.low-latency": "false",
        "mapreduce.input.lineinputformat.linespermap": "1",
        "ipc.client.connect.max.retries.on.timeouts": "45",
        "yarn.timeline-service.leveldb-timeline-store.read-cache-size": "104857600",
        "yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs": "*********(redacted)",
        "yarn.timeline-service.entity-group-fs-store.app-cache-size": "10",
        "yarn.resourcemanager.resource-tracker.address": "${yarn.resourcemanager.hostname}:8031",
        "yarn.nodemanager.node-labels.provider.fetch-timeout-ms": "1200000",
        "mapreduce.job.heap.memory-mb.ratio": "0.8",
        "yarn.resourcemanager.leveldb-state-store.compaction-interval-secs": "3600",
        "yarn.resourcemanager.webapp.rest-csrf.custom-header": "X-XSRF-Header",
        "yarn.nodemanager.pluggable-device-framework.enabled": "false",
        "mapreduce.client.output.filter": "FAILED",
        "hadoop.http.filter.initializers": "org.apache.hadoop.http.lib.StaticUserWebFilter",
        "mapreduce.fileoutputcommitter.task.cleanup.enabled": "false",
        "ipc.[port_number].weighted-cost.lockfree": "1",
        "yarn.nodemanager.opportunistic-containers-max-queue-length": "0",
        "yarn.resourcemanager.state-store.max-completed-applications": "${yarn.resourcemanager.max-completed-applications}",
        "mapreduce.job.speculative.minimum-allowed-tasks": "10",
        "fs.s3a.aws.credentials.provider": "\n    org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider,\n    org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider,\n    com.amazonaws.auth.EnvironmentVariableCredentialsProvider,\n    org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider\n  ",
        "yarn.log-aggregation.retain-seconds": "-1",
        "yarn.timeline-service.hostname": "0.0.0.0",
        "file.replication": "1",
        "yarn.nodemanager.container-metrics.unregister-delay-ms": "10000",
        "yarn.nodemanager.container-metrics.period-ms": "-1",
        "yarn.nodemanager.log.retain-seconds": "10800",
        "yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds": "3600",
        "ipc.[port_number].callqueue.impl": "java.util.concurrent.LinkedBlockingQueue",
        "yarn.resourcemanager.keytab": "/etc/krb5.keytab",
        "hadoop.security.group.mapping.providers.combined": "true",
        "mapreduce.reduce.merge.inmem.threshold": "1000",
        "yarn.timeline-service.recovery.enabled": "false",
        "fs.azure.saskey.usecontainersaskeyforallaccess": "true",
        "yarn.sharedcache.nm.uploader.thread-count": "20",
        "yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs": "3600",
        "mapreduce.shuffle.ssl.enabled": "false",
        "yarn.timeline-service.hbase.coprocessor.app-final-value-retention-milliseconds": "259200000",
        "yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb": "0",
        "mapreduce.jobhistory.max-age-ms": "604800000",
        "hadoop.http.cross-origin.allowed-methods": "GET,POST,HEAD",
        "yarn.resourcemanager.opportunistic-container-allocation.enabled": "false",
        "mapreduce.jobhistory.webapp.address": "0.0.0.0:19888",
        "hadoop.system.tags": "YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL",
        "yarn.log-aggregation.file-controller.TFile.class": "org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController",
        "yarn.client.nodemanager-connect.max-wait-ms": "180000",
        "yarn.resourcemanager.webapp.address": "${yarn.resourcemanager.hostname}:8088",
        "mapreduce.jobhistory.recovery.enable": "false",
        "mapreduce.reduce.shuffle.parallelcopies": "5",
        "yarn.app.mapreduce.client.max-retries": "3",
        "hadoop.security.authentication": "simple",
        "fs.s3a.select.input.csv.comment.marker": "#",
        "mapreduce.job.queuename": "default",
        "mapreduce.job.encrypted-intermediate-data-key-size-bits": "128",
        "yarn.nodemanager.webapp.xfs-filter.xframe-options": "SAMEORIGIN",
        "fs.AbstractFileSystem.webhdfs.impl": "org.apache.hadoop.fs.WebHdfs",
        "fs.trash.interval": "0",
        "mapreduce.task.profile.reduce.params": "${mapreduce.task.profile.params}",
        "yarn.app.mapreduce.am.resource.mb": "1536",
        "mapreduce.input.fileinputformat.list-status.num-threads": "1",
        "yarn.nodemanager.container-executor.class": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "io.mapfile.bloom.size": "1048576",
        "yarn.timeline-service.ttl-ms": "604800000",
        "yarn.resourcemanager.nm-container-queuing.min-queue-length": "5",
        "yarn.nodemanager.resource.cpu-vcores": "-1",
        "mapreduce.job.reduces": "1",
        "fs.s3a.multipart.size": "64M",
        "yarn.scheduler.minimum-allocation-vcores": "1",
        "mapreduce.job.speculative.speculative-cap-total-tasks": "0.01",
        "hadoop.ssl.client.conf": "ssl-client.xml",
        "fs.s3a.metadatastore.authoritative": "false",
        "ipc.[port_number].weighted-cost.response": "1",
        "ha.health-monitor.sleep-after-disconnect.ms": "1000",
        "yarn.app.mapreduce.shuffle.log.limit.kb": "0",
        "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback",
        "yarn.client.application-client-protocol.poll-timeout-ms": "-1",
        "yarn.resourcemanager.application.max-tag.length": "100",
        "hadoop.http.staticuser.user": "dr.who",
        "yarn.nodemanager.linux-container-executor.resources-handler.class": "org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler",
        "mapreduce.reduce.shuffle.memory.limit.percent": "0.25",
        "yarn.resourcemanager.reservation-system.enable": "false",
        "mapreduce.map.output.compress": "false",
        "ha.zookeeper.acl": "world:anyone:rwcda",
        "ipc.server.max.connections": "0",
        "yarn.nodemanager.runtime.linux.docker.default-container-network": "host",
        "yarn.router.webapp.address": "0.0.0.0:8089",
        "yarn.scheduler.maximum-allocation-mb": "8192",
        "yarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidia-docker-v1.endpoint": "http://localhost:3476/v1.0/docker/cli",
        "yarn.app.mapreduce.am.container.log.limit.kb": "0",
        "mapreduce.jobhistory.jhist.format": "binary",
        "mapreduce.task.stuck.timeout-ms": "600000",
        "yarn.resourcemanager.ha.enabled": "false",
        "dfs.client.ignore.namenode.default.kms.uri": "false",
        "mapreduce.task.exit.timeout.check-interval-ms": "20000",
        "mapreduce.jobhistory.intermediate-user-done-dir.permissions": "770",
        "mapreduce.task.exit.timeout": "60000",
        "yarn.resourcemanager.scheduler.monitor.policies": "org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy",
        "yarn.sharedcache.cleaner.period-mins": "1440",
        "ipc.client.connect.retry.interval": "1000",
        "yarn.timeline-service.http-cross-origin.enabled": "false",
        "fs.wasbs.impl": "org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure",
        "yarn.resourcemanager.nodemanagers.heartbeat-interval-max-ms": "1000",
        "yarn.federation.subcluster-resolver.class": "org.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl",
        "yarn.resourcemanager.zk-state-store.parent-path": "/rmstore",
        "fs.s3a.select.input.csv.field.delimiter": ",",
        "mapreduce.jobhistory.cleaner.enable": "true",
        "yarn.timeline-service.client.fd-flush-interval-secs": "10",
        "hadoop.security.kms.client.encrypted.key.cache.expiry": "43200000",
        "yarn.resourcemanager.nm-container-queuing.sorting-nodes-interval-ms": "1000",
        "fs.s3a.committer.staging.tmp.path": "tmp/staging",
        "yarn.nodemanager.sleep-delay-before-sigkill.ms": "250",
        "yarn.nodemanager.resource.count-logical-processors-as-cores": "false",
        "hadoop.registry.zk.root": "/registry",
        "mapreduce.client.libjars.wildcard": "true",
        "fs.s3a.committer.staging.unique-filenames": "true",
        "yarn.nodemanager.node-attributes.provider.fetch-timeout-ms": "1200000",
        "yarn.client.nodemanager-client-async.thread-pool-max-size": "500",
        "mapreduce.map.maxattempts": "4",
        "yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms": "10",
        "mapreduce.job.end-notification.retry.attempts": "0",
        "adl.feature.ownerandgroup.enableupn": "false",
        "yarn.resourcemanager.zk-max-znode-size.bytes": "1048576",
        "mapreduce.job.reduce.shuffle.consumer.plugin.class": "org.apache.hadoop.mapreduce.task.reduce.Shuffle",
        "yarn.resourcemanager.delayed.delegation-token.removal-interval-ms": "*********(redacted)",
        "yarn.nodemanager.localizer.cache.target-size-mb": "10240",
        "fs.s3a.committer.staging.conflict-mode": "append",
        "fs.s3a.list.version": "2",
        "ftp.client-write-packet-size": "65536",
        "yarn.nodemanager.container-log-monitor.enable": "false",
        "hadoop.security.key.default.cipher": "AES/CTR/NoPadding",
        "mapreduce.job.local-fs.single-disk-limit.check.interval-ms": "5000",
        "net.topology.node.switch.mapping.impl": "org.apache.hadoop.net.ScriptBasedMapping",
        "ipc.[port_number].decay-scheduler.period-ms": "5000",
        "yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.cache-refresh-interval-secs": "60",
        "map.sort.class": "org.apache.hadoop.util.QuickSort",
        "fs.viewfs.rename.strategy": "SAME_MOUNTPOINT",
        "hadoop.security.kms.client.authentication.retry-count": "1",
        "yarn.nodemanager.runtime.linux.runc.privileged-containers.allowed": "false",
        "ipc.[port_number].weighted-cost.lockexclusive": "100",
        "fs.AbstractFileSystem.adl.impl": "org.apache.hadoop.fs.adl.Adl",
        "yarn.client.failover-retries": "0",
        "fs.s3a.multipart.purge.age": "86400",
        "yarn.nodemanager.amrmproxy.address": "0.0.0.0:8049",
        "ipc.server.listen.queue.size": "256",
        "fs.permissions.umask-mode": "022",
        "fs.s3a.assumed.role.credentials.provider": "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider",
        "yarn.nodemanager.vmem-check-enabled": "true",
        "yarn.nodemanager.health-checker.run-before-startup": "false",
        "mapreduce.job.max.map": "-1",
        "mapreduce.job.ubertask.maxreduces": "1",
        "mapreduce.shuffle.pathcache.max-weight": "10485760",
        "hadoop.security.kms.client.encrypted.key.cache.size": "500",
        "yarn.nodemanager.env-whitelist": "JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ",
        "yarn.registry.class": "org.apache.hadoop.registry.client.impl.FSRegistryOperationsService",
        "mapreduce.jobhistory.admin.acl": "*",
        "yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size": "10",
        "yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-size": "500",
        "yarn.timeline-service.webapp.rest-csrf.enabled": "false",
        "yarn.nodemanager.disk-health-checker.min-free-space-per-disk-watermark-high-mb": "0",
        "yarn.nodemanager.numa-awareness.enabled": "false",
        "yarn.nodemanager.recovery.compaction-interval-secs": "3600",
        "yarn.app.mapreduce.client-am.ipc.max-retries": "3",
        "yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.interval-seconds": "60",
        "yarn.federation.registry.base-dir": "yarnfederation/",
        "mapreduce.job.local-fs.single-disk-limit.bytes": "-1",
        "mapreduce.shuffle.pathcache.concurrency-level": "16",
        "hadoop.security.java.secure.random.algorithm": "SHA1PRNG",
        "ha.failover-controller.cli-check.rpc-timeout.ms": "20000",
        "mapreduce.jobhistory.jobname.limit": "50",
        "fs.s3a.select.input.compression": "none",
        "yarn.client.nodemanager-connect.retry-interval-ms": "10000",
        "ipc.[port_number].scheduler.priority.levels": "4",
        "yarn.timeline-service.state-store-class": "org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore",
        "yarn.sharedcache.nested-level": "3",
        "yarn.timeline-service.webapp.rest-csrf.methods-to-ignore": "GET,OPTIONS,HEAD",
        "fs.azure.user.agent.prefix": "unknown",
        "yarn.resourcemanager.zk-delegation-token-node.split-index": "*********(redacted)",
        "yarn.nodemanager.numa-awareness.read-topology": "false",
        "yarn.nodemanager.webapp.address": "${yarn.nodemanager.hostname}:8042",
        "rpc.metrics.quantile.enable": "false",
        "yarn.scheduler.queue-placement-rules": "user-group",
        "hadoop.http.authentication.kerberos.keytab": "${user.home}/hadoop.keytab",
        "yarn.resourcemanager.recovery.enabled": "false",
        "fs.s3a.select.input.csv.header": "none"
    },
    "System Properties": {
        "java.io.tmpdir": "/tmp",
        "line.separator": "\n",
        "path.separator": ":",
        "user.home": "/home/chenhao",
        "file.separator": "/",
        "user.timezone": "PRC",
        "sun.os.patch.level": "unknown",
        "java.vm.specification.vendor": "Oracle Corporation",
        "user.country": "US",
        "awt.toolkit": "sun.awt.X11.XToolkit",
        "os.name": "Linux",
        "sun.management.compiler": "HotSpot 64-Bit Tiered Compilers",
        "sun.cpu.endian": "little",
        "java.specification.version": "11",
        "java.vm.specification.name": "Java Virtual Machine Specification",
        "java.vendor": "Oracle Corporation",
        "java.vm.specification.version": "11",
        "sun.arch.data.model": "64",
        "sun.boot.library.path": "/home/chenhao/libs/jdk11/lib",
        "user.dir": "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/work/driver-20230404174339-0001",
        "java.library.path": "/usr/lib64:/lib64:/public/software/gcc/lib64:/public/software//mpi/openmpi/1.8.7/intel/lib/openmpi:/public/software//mpi/openmpi/1.8.7/intel/lib:/public/software/compiler/composer_xe_2015.0.090/compiler/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/mpirt/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/ipp/../compiler/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/ipp/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/compiler/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/mkl/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/tbb/lib/intel64/gcc4.4:/public/software/compiler/composer_xe_2015.0.090/compiler/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/mpirt/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/ipp/../compiler/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/ipp/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/compiler/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/mkl/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/tbb/lib/intel64/gcc4.4:/public/software/compiler/composer_xe_2015.0.090/compiler/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/mpirt/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/ipp/../compiler/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/ipp/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/compiler/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/mkl/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/tbb/lib/intel64/gcc4.4:/public/software/g09/bsd:/public/software/g09/local:/public/software/g09/extras:/public/software/g09:/opt/gridview//pbs//dispatcher//lib:/public/software/compiler/composer_xe_2015.0.090/compiler/lib/intel64:/public/software/compiler/composer_xe_2015.0.090/mkl/lib/intel64::/usr/local/lib64:/usr/local/lib:/public/software/g09:/public/software/gv/lib:/public/software/MaterialsStudio8.0/lib:/public/software/MaterialsStudio8.0/lib/32:/public/software/gcc/mpc/lib:/opt/hadoop/hadoop-2.7.6-5nodes/lib/native:/usr/local/lib/libdisni/lib:/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib",
        "sun.cpu.isalist": "",
        "os.arch": "amd64",
        "java.vm.version": "11.0.16.1+1-LTS-1",
        "jetty.git.hash": "6b67c5719d1f4371b33655ff2d047d24e171e49a",
        "java.runtime.version": "11.0.16.1+1-LTS-1",
        "java.vm.info": "mixed mode",
        "java.runtime.name": "Java(TM) SE Runtime Environment",
        "java.version.date": "2022-08-18",
        "java.class.version": "55.0",
        "java.specification.name": "Java Platform API Specification",
        "file.encoding": "UTF-8",
        "java.specification.vendor": "Oracle Corporation",
        "sun.java.launcher": "SUN_STANDARD",
        "java.vm.compressedOopsMode": "32-bit",
        "os.version": "2.6.32-220.el6.x86_64",
        "sun.jnu.encoding": "UTF-8",
        "user.language": "en",
        "java.vendor.version": "18.9",
        "java.vendor.url": "https://openjdk.java.net/",
        "java.awt.printerjob": "sun.print.PSPrinterJob",
        "java.awt.graphicsenv": "sun.awt.X11GraphicsEnvironment",
        "java.vm.vendor": "Oracle Corporation",
        "jdk.debug": "release",
        "java.vendor.url.bug": "https://bugreport.java.com/bugreport/",
        "user.name": "chenhao",
        "java.vm.name": "Java HotSpot(TM) 64-Bit Server VM",
        "sun.java.command": "org.apache.spark.deploy.worker.DriverWrapper spark://Worker@11.11.0.86:37019 /home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/work/driver-20230404174339-0001/SparkTemplate-1.3-jar-with-dependencies.jar name.spade5.Main",
        "java.home": "/home/chenhao/libs/jdk11",
        "java.version": "11.0.16.1",
        "sun.io.unicode.encoding": "UnicodeLittle"
    },
    "Classpath Entries": {
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/javolution-5.5.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-serde-2.3.9.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/datanucleus-core-4.1.17.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-storageclass-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spire-util_2.13-0.17.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-beeline-2.3.9.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/scala-reflect-2.13.8.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/javassist-3.25.0-GA.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-transport-native-kqueue-4.1.74.Final-osx-x86_64.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-llap-common-2.3.9.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-yarn_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/libthrift-0.12.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/cats-kernel_2.13-2.1.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spire_2.13-0.17.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-service-rpc-3.1.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/parquet-encoding-1.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/arpack_combined_all-0.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jackson-core-2.13.4.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/json4s-scalap_2.13-3.7.0-M11.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-autoscaling-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jdo-api-3.0.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/minlog-1.3.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/metrics-graphite-4.2.7.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-discovery-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-codec-1.15.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/httpcore-4.4.14.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/json-1.8.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/protobuf-java-2.5.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/guava-14.0.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spire-macros_2.13-0.17.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/HikariCP-2.5.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/rocksdbjni-6.20.3.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/chill-java-0.10.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-resolver-4.1.74.Final.jar": "System Classpath",
        "spark://node86:42755/jars/SparkTemplate-1.3-jar-with-dependencies.jar": "Added By User",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jakarta.servlet-api-4.0.3.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hadoop-client-runtime-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jna-5.9.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-logging-1.1.3.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/chill_2.13-0.10.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-math3-3.6.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-tags_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-cli-1.5.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/curator-recipes-2.13.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jersey-client-2.36.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/parquet-format-structures-1.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/json4s-ast_2.13-3.7.0-M11.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/osgi-resource-locator-1.0.3.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/compress-lzf-1.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/curator-framework-2.13.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/conf/": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/datanucleus-rdbms-4.1.19.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/oro-2.0.8.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/xz-1.9.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-cli-2.3.9.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-shims-0.23-2.3.9.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-jdbc-2.3.9.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/leveldbjni-all-1.8.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/scala-parser-combinators_2.13-1.1.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/zstd-jni-1.5.2-1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-metastore-2.3.9.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-graphx_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/threeten-extra-1.5.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/JTransforms-3.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/log4j-core-2.17.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/flatbuffers-java-1.12.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-tags_2.13-3.3.2-tests.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/istack-commons-runtime-3.0.8.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jackson-mapper-asl-1.9.13.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jersey-common-2.36.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-network-shuffle_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-coordination-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/annotations-17.0.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/avro-ipc-1.11.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/parquet-jackson-1.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/univocity-parsers-2.9.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/log4j-api-2.17.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-transport-native-epoll-4.1.74.Final-linux-x86_64.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jakarta.validation-api-2.0.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jakarta.xml.bind-api-2.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/slf4j-api-1.7.32.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jakarta.annotation-api-1.3.5.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/json4s-jackson_2.13-3.7.0-M11.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jpam-1.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/lz4-java-1.8.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-collections4-4.4.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/gson-2.2.4.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-buffer-4.1.74.Final.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-tcnative-classes-2.0.48.Final.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-extensions-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/orc-core-1.7.8.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-transport-4.1.74.Final.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/scala-collection-compat_2.13-2.1.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-io-2.11.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/metrics-core-4.2.7.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/zjsonpatch-0.3.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/paranamer-2.8.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/lapack-2.2.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/tink-1.6.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hadoop-client-api-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hk2-locator-2.6.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/okio-1.14.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/bonecp-0.8.0.RELEASE.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/snappy-java-1.1.8.4.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jersey-hk2-2.36.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spire-platform_2.13-0.17.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-mllib-local_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/JLargeArrays-1.5.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-unsafe_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/core-1.1.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jackson-module-scala_2.13-2.13.4.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-transport-native-epoll-4.1.74.Final-linux-aarch_64.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/breeze-macros_2.13-1.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/httpclient-4.5.13.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jta-1.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/derby-10.14.2.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-sql_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jakarta.inject-2.6.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/scala-compiler-2.13.8.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-vector-code-gen-2.3.9.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-metrics-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/curator-client-2.13.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-shims-common-2.3.9.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/zookeeper-3.6.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/antlr4-runtime-4.8.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jersey-container-servlet-2.36.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/algebra_2.13-2.0.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-compiler-3.0.16.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/datanucleus-api-jdo-4.2.4.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/stream-2.9.6.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/janino-3.0.16.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/shapeless_2.13-2.3.7.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-transport-classes-epoll-4.1.74.Final.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/zookeeper-jute-3.6.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/stax-api-1.0.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/pickle-1.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-dbcp-1.4.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jline-3.21.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/arrow-vector-7.0.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-pool-1.5.4.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/scala-library-2.13.8.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jackson-dataformat-yaml-2.13.4.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-repl_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/metrics-json-4.2.7.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/shims-0.9.25.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/json4s-core_2.13-3.7.0-M11.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-shims-scheduler-2.3.9.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-common-2.3.9.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-launcher_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/opencsv-2.3.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-lang-2.6.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/aopalliance-repackaged-2.6.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-text-1.10.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-shims-2.3.9.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hadoop-yarn-server-web-proxy-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/transaction-api-1.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/okhttp-3.12.12.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-mllib_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hk2-utils-2.6.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jcl-over-slf4j-1.7.32.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-node-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/arrow-memory-core-7.0.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jackson-annotations-2.13.4.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/ivy-2.5.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jakarta.ws.rs-api-2.1.6.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hadoop-shaded-guava-1.1.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/arrow-format-7.0.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/audience-annotations-0.5.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-networking-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jline-2.14.6.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-events-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-exec-2.3.9-core.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/avro-mapred-1.11.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/metrics-jvm-4.2.7.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-kubernetes_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-transport-native-kqueue-4.1.74.Final-osx-aarch_64.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/metrics-jmx-4.2.7.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/javax.jdo-3.2.0-m3.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-collections-3.2.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-hive_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/arrow-memory-netty-7.0.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jul-to-slf4j-1.7.32.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jaxb-runtime-2.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-all-4.1.74.Final.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-lang3-3.12.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/avro-1.11.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-sketch_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jsr305-3.0.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-client-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/breeze_2.13-1.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-flowcontrol-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-network-common_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/scala-parallel-collections_2.13-1.0.3.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/objenesis-3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-admissionregistration-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-apps-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-streaming_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/logging-interceptor-3.12.12.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/orc-mapreduce-1.7.8.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-transport-classes-kqueue-4.1.74.Final.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/antlr-runtime-3.5.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-kvstore_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-common-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-core_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/scala-xml_2.13-1.2.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-common-4.1.74.Final.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-policy-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-handler-4.1.74.Final.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-apiextensions-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hk2-api-2.6.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/velocity-1.5.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/hive-storage-api-2.7.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/parquet-common-1.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-catalyst_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/activation-1.1.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/xbean-asm9-shaded-4.20.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-rbac-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jersey-container-servlet-core-2.36.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kryo-shaded-4.0.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jersey-server-2.36.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/blas-2.2.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/libfb303-0.9.3.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/joda-time-2.10.13.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-scheduling-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jackson-core-asl-1.9.13.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/generex-1.0.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/RoaringBitmap-0.9.25.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jodd-core-3.5.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/aircompressor-0.21.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-batch-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/parquet-hadoop-1.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-hive-thriftserver_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/log4j-slf4j-impl-2.17.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/py4j-0.10.9.5.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/ST4-4.0.4.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-compress-1.21.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/automaton-1.11-8.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-core-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/commons-crypto-1.1.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/orc-shims-1.7.8.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-codec-4.1.74.Final.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/netty-transport-native-unix-common-4.1.74.Final.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/super-csv-2.2.0.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/log4j-1.2-api-2.17.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/parquet-column-1.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/spark-mesos_2.13-3.3.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jackson-databind-2.13.4.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/kubernetes-model-certificates-5.12.2.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/jackson-datatype-jsr310-2.13.4.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/arpack-2.2.1.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/snakeyaml-1.31.jar": "System Classpath",
        "/home/chenhao/libs/spark-3.3.2-bin-hadoop3-scala2.13/jars/mesos-1.4.3-shaded-protobuf.jar": "System Classpath"
    }
}
{
    "Event": "SparkListenerApplicationStart",
    "App Name": "WordCount",
    "App ID": "app-20230404174343-0001",
    "Timestamp": 1680601037564,
    "User": "chenhao",
    "Driver Logs": {
        "stderr": "http://11.11.0.86:8081/logPage/?driverId=driver-20230404174339-0001&logType=stderr",
        "stdout": "http://11.11.0.86:8081/logPage/?driverId=driver-20230404174339-0001&logType=stdout"
    }
}
{
    "Event": "SparkListenerJobStart",
    "Job ID": 0,
    "Submission Time": 1680601040618,
    "Stage Infos": [
        {
            "Stage ID": 0,
            "Stage Attempt ID": 0,
            "Stage Name": "map at main.scala:46",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 2,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"3\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
                    "Callsite": "map at main.scala:46",
                    "Parent IDs": [
                        1
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 0,
                    "Name": "KafkaRDD",
                    "Scope": "{\"id\":\"0_1680601040000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:20\"}",
                    "Callsite": "createDirectStream at main.scala:31",
                    "Parent IDs": [],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 1,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"2\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
                    "Callsite": "flatMap at main.scala:41",
                    "Parent IDs": [
                        0
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [],
            "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
            "Accumulables": [],
            "Resource Profile Id": 0
        },
        {
            "Stage ID": 1,
            "Stage Attempt ID": 0,
            "Stage Name": "runJob at SparkHadoopWriter.scala:83",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 4,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"5\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
                    "Callsite": "saveAsTextFile at main.scala:48",
                    "Parent IDs": [
                        3
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 3,
                    "Name": "ShuffledRDD",
                    "Scope": "{\"id\":\"4\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
                    "Callsite": "reduceByKey at main.scala:46",
                    "Parent IDs": [
                        2
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [
                0
            ],
            "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
            "Accumulables": [],
            "Resource Profile Id": 0
        }
    ],
    "Stage IDs": [
        0,
        1
    ],
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"5\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
        "spark.job.interruptOnCancel": "false",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601040000\">[output operation 0, batch time 17:37:20]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601040000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 0,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 2,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"3\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    1
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 0,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601040000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:20\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 1,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"2\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    0
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601040671,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"5\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601040000\">[output operation 0, batch time 17:37:20]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601040000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerExecutorAdded",
    "Timestamp": 1680601041555,
    "Executor ID": "1",
    "Executor Info": {
        "Host": "11.11.0.85",
        "Total Cores": 1,
        "Log Urls": {
            "stderr": "http://11.11.0.85:8081/logPage/?appId=app-20230404174343-0001&executorId=1&logType=stderr",
            "stdout": "http://11.11.0.85:8081/logPage/?appId=app-20230404174343-0001&executorId=1&logType=stdout"
        },
        "Attributes": {},
        "Resources": {},
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerExecutorAdded",
    "Timestamp": 1680601041585,
    "Executor ID": "0",
    "Executor Info": {
        "Host": "11.11.0.87",
        "Total Cores": 1,
        "Log Urls": {
            "stderr": "http://11.11.0.87:8081/logPage/?appId=app-20230404174343-0001&executorId=0&logType=stderr",
            "stdout": "http://11.11.0.87:8081/logPage/?appId=app-20230404174343-0001&executorId=0&logType=stdout"
        },
        "Attributes": {},
        "Resources": {},
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerBlockManagerAdded",
    "Block Manager ID": {
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Port": 57555
    },
    "Maximum Memory": 455501414,
    "Timestamp": 1680601041645,
    "Maximum Onheap Memory": 455501414,
    "Maximum Offheap Memory": 0
}
{
    "Event": "SparkListenerBlockManagerAdded",
    "Block Manager ID": {
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Port": 35936
    },
    "Maximum Memory": 455501414,
    "Timestamp": 1680601041680,
    "Maximum Onheap Memory": 455501414,
    "Maximum Offheap Memory": 0
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 0,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 0,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601043892,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 0,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 1,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601045449,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 0,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 0,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601043892,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601048037,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 0,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 628,
                "Value": 628,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 1,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 334751682,
                "Value": 334751682,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 2,
                "Name": "internal.metrics.executorRunTime",
                "Update": 3403,
                "Value": 3403,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 3,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 3307187644,
                "Value": 3307187644,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 4,
                "Name": "internal.metrics.resultSize",
                "Update": 1338,
                "Value": 1338,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 5,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 68,
                "Value": 68,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 6,
                "Name": "internal.metrics.resultSerializationTime",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 7,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 8,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 9,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 20794645,
                "Value": 20794645,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 18,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 2851929,
                "Value": 2851929,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 19,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 206675,
                "Value": 206675,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 20,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 6234581,
                "Value": 6234581,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 628,
        "Executor Deserialize CPU Time": 334751682,
        "Executor Run Time": 3403,
        "Executor CPU Time": 3307187644,
        "Peak Execution Memory": 20794645,
        "Result Size": 1338,
        "JVM GC Time": 68,
        "Result Serialization Time": 1,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 2851929,
            "Shuffle Write Time": 6234581,
            "Shuffle Records Written": 206675
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 0,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 1,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601045449,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601049184,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 0,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 419,
                "Value": 1047,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 1,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 335840940,
                "Value": 670592622,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 2,
                "Name": "internal.metrics.executorRunTime",
                "Update": 3267,
                "Value": 6670,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 3,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 3163929346,
                "Value": 6471116990,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 4,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 2633,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 5,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 67,
                "Value": 135,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 7,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 8,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 9,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 26691252,
                "Value": 47485897,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 18,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 2851772,
                "Value": 5703701,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 19,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 206540,
                "Value": 413215,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 20,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 6471651,
                "Value": 12706232,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 419,
        "Executor Deserialize CPU Time": 335840940,
        "Executor Run Time": 3267,
        "Executor CPU Time": 3163929346,
        "Peak Execution Memory": 26691252,
        "Result Size": 1295,
        "JVM GC Time": 67,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 2851772,
            "Shuffle Write Time": 6471651,
            "Shuffle Records Written": 206540
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 0,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 2,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"3\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    1
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 0,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601040000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:20\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 1,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"2\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    0
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601040671,
        "Completion Time": 1680601049189,
        "Accumulables": [
            {
                "ID": 0,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 1047,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 1,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 670592622,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 2,
                "Name": "internal.metrics.executorRunTime",
                "Value": 6670,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 3,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 6471116990,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 4,
                "Name": "internal.metrics.resultSize",
                "Value": 2633,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 5,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 135,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 6,
                "Name": "internal.metrics.resultSerializationTime",
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 7,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 8,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 9,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 47485897,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 18,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Value": 5703701,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 19,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Value": 413215,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 20,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Value": 12706232,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 1,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 4,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"5\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    3
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 3,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"4\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    2
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            0
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601049209,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"5\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601040000\">[output operation 0, batch time 17:37:20]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601040000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 1,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 2,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601049239,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 1,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 3,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601049242,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 1,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 3,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601049242,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601050234,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 25,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 122,
                "Value": 122,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 26,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 91888486,
                "Value": 91888486,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 27,
                "Name": "internal.metrics.executorRunTime",
                "Update": 851,
                "Value": 851,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 28,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 798219831,
                "Value": 798219831,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 29,
                "Name": "internal.metrics.resultSize",
                "Update": 1823,
                "Value": 1823,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 31,
                "Name": "internal.metrics.resultSerializationTime",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 32,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 33,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 34,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 12225218,
                "Value": 12225218,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 36,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 37,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 38,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1424106,
                "Value": 1424106,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 39,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 40,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1417587,
                "Value": 1417587,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 41,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 42,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 205870,
                "Value": 205870,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 48,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4441254,
                "Value": 4441254,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 49,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 171311,
                "Value": 171311,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 122,
        "Executor Deserialize CPU Time": 91888486,
        "Executor Run Time": 851,
        "Executor CPU Time": 798219831,
        "Peak Execution Memory": 12225218,
        "Result Size": 1823,
        "JVM GC Time": 0,
        "Result Serialization Time": 1,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1424106,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1417587,
            "Total Records Read": 205870
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4441254,
            "Records Written": 171311
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 1,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 2,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601049239,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601050237,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 25,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 86,
                "Value": 208,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 26,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 73837166,
                "Value": 165725652,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 27,
                "Name": "internal.metrics.executorRunTime",
                "Update": 889,
                "Value": 1740,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 28,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 803794382,
                "Value": 1602014213,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 29,
                "Name": "internal.metrics.resultSize",
                "Update": 1823,
                "Value": 3646,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 31,
                "Name": "internal.metrics.resultSerializationTime",
                "Update": 2,
                "Value": 3,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 32,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 33,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 34,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 11450011,
                "Value": 23675229,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 36,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 37,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 38,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1434185,
                "Value": 2858291,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 39,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 40,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1427823,
                "Value": 2845410,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 41,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 42,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 207345,
                "Value": 413215,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 48,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4480840,
                "Value": 8922094,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 49,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 172457,
                "Value": 343768,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 86,
        "Executor Deserialize CPU Time": 73837166,
        "Executor Run Time": 889,
        "Executor CPU Time": 803794382,
        "Peak Execution Memory": 11450011,
        "Result Size": 1823,
        "JVM GC Time": 0,
        "Result Serialization Time": 2,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1434185,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1427823,
            "Total Records Read": 207345
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4480840,
            "Records Written": 172457
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 1,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 4,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"5\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    3
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 3,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"4\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601040000\",\"name\":\"foreachRDD @ 17:37:20\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    2
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            0
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601049209,
        "Completion Time": 1680601050238,
        "Accumulables": [
            {
                "ID": 25,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 208,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 26,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 165725652,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 27,
                "Name": "internal.metrics.executorRunTime",
                "Value": 1740,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 28,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 1602014213,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 29,
                "Name": "internal.metrics.resultSize",
                "Value": 3646,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 31,
                "Name": "internal.metrics.resultSerializationTime",
                "Value": 3,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 32,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 33,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 34,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 23675229,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 36,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 37,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 38,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Value": 2858291,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 39,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 40,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Value": 2845410,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 41,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 42,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Value": 413215,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 48,
                "Name": "internal.metrics.output.bytesWritten",
                "Value": 8922094,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 49,
                "Name": "internal.metrics.output.recordsWritten",
                "Value": 343768,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerJobEnd",
    "Job ID": 0,
    "Completion Time": 1680601050243,
    "Job Result": {
        "Result": "JobSucceeded"
    }
}
{
    "Event": "SparkListenerJobStart",
    "Job ID": 1,
    "Submission Time": 1680601050396,
    "Stage Infos": [
        {
            "Stage ID": 2,
            "Stage Attempt ID": 0,
            "Stage Name": "map at main.scala:46",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 16,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"12\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
                    "Callsite": "map at main.scala:46",
                    "Parent IDs": [
                        15
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 15,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"11\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
                    "Callsite": "flatMap at main.scala:41",
                    "Parent IDs": [
                        5
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 5,
                    "Name": "KafkaRDD",
                    "Scope": "{\"id\":\"0_1680601041000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:21\"}",
                    "Callsite": "createDirectStream at main.scala:31",
                    "Parent IDs": [],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [],
            "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
            "Accumulables": [],
            "Resource Profile Id": 0
        },
        {
            "Stage ID": 3,
            "Stage Attempt ID": 0,
            "Stage Name": "runJob at SparkHadoopWriter.scala:83",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 18,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"14\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
                    "Callsite": "saveAsTextFile at main.scala:48",
                    "Parent IDs": [
                        17
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 17,
                    "Name": "ShuffledRDD",
                    "Scope": "{\"id\":\"13\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
                    "Callsite": "reduceByKey at main.scala:46",
                    "Parent IDs": [
                        16
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [
                2
            ],
            "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
            "Accumulables": [],
            "Resource Profile Id": 0
        }
    ],
    "Stage IDs": [
        2,
        3
    ],
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"14\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
        "spark.job.interruptOnCancel": "false",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601041000\">[output operation 0, batch time 17:37:21]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601041000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 2,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 16,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"12\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    15
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 15,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"11\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    5
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 5,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601041000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:21\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601050400,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"14\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601041000\">[output operation 0, batch time 17:37:21]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601041000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 2,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 4,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601050414,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 2,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 5,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601050415,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 2,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 4,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601050414,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601051862,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 50,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 26,
                "Value": 26,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 51,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 15850170,
                "Value": 15850170,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 52,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1407,
                "Value": 1407,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 53,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1366861149,
                "Value": 1366861149,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 54,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 1295,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 55,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 31,
                "Value": 31,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 57,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 58,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 59,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 30763747,
                "Value": 30763747,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 68,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 3040832,
                "Value": 3040832,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 69,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 218417,
                "Value": 218417,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 70,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 4596643,
                "Value": 4596643,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 26,
        "Executor Deserialize CPU Time": 15850170,
        "Executor Run Time": 1407,
        "Executor CPU Time": 1366861149,
        "Peak Execution Memory": 30763747,
        "Result Size": 1295,
        "JVM GC Time": 31,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 3040832,
            "Shuffle Write Time": 4596643,
            "Shuffle Records Written": 218417
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 2,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 5,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601050415,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601052140,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 50,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 21,
                "Value": 47,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 51,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 12010197,
                "Value": 27860367,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 52,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1688,
                "Value": 3095,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 53,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1605632643,
                "Value": 2972493792,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 54,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 55,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 31,
                "Value": 62,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 57,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 58,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 59,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 26246954,
                "Value": 57010701,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 68,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 2963271,
                "Value": 6004103,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 69,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 216519,
                "Value": 434936,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 70,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 4030141,
                "Value": 8626784,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 21,
        "Executor Deserialize CPU Time": 12010197,
        "Executor Run Time": 1688,
        "Executor CPU Time": 1605632643,
        "Peak Execution Memory": 26246954,
        "Result Size": 1295,
        "JVM GC Time": 31,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 2963271,
            "Shuffle Write Time": 4030141,
            "Shuffle Records Written": 216519
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 2,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 16,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"12\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    15
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 15,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"11\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    5
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 5,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601041000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:21\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601050400,
        "Completion Time": 1680601052141,
        "Accumulables": [
            {
                "ID": 50,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 47,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 51,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 27860367,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 52,
                "Name": "internal.metrics.executorRunTime",
                "Value": 3095,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 53,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 2972493792,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 54,
                "Name": "internal.metrics.resultSize",
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 55,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 62,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 57,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 58,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 59,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 57010701,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 68,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Value": 6004103,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 69,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Value": 434936,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 70,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Value": 8626784,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 3,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 18,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"14\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    17
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 17,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"13\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    16
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            2
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601052144,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"14\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601041000\">[output operation 0, batch time 17:37:21]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601041000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 3,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 6,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601052171,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 3,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 7,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601052172,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 3,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 6,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601052171,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601052638,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 75,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 37,
                "Value": 37,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 76,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 27763631,
                "Value": 27763631,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 77,
                "Name": "internal.metrics.executorRunTime",
                "Update": 416,
                "Value": 416,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 78,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 351089800,
                "Value": 351089800,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 79,
                "Name": "internal.metrics.resultSize",
                "Update": 1823,
                "Value": 1823,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 80,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 25,
                "Value": 25,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 82,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 83,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 84,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 14572957,
                "Value": 14572957,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 86,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 87,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 88,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1473708,
                "Value": 1473708,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 89,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 90,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1526185,
                "Value": 1526185,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 91,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 92,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 217913,
                "Value": 217913,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 98,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4624830,
                "Value": 4624830,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 99,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 181981,
                "Value": 181981,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 37,
        "Executor Deserialize CPU Time": 27763631,
        "Executor Run Time": 416,
        "Executor CPU Time": 351089800,
        "Peak Execution Memory": 14572957,
        "Result Size": 1823,
        "JVM GC Time": 25,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1473708,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1526185,
            "Total Records Read": 217913
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4624830,
            "Records Written": 181981
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 3,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 7,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601052172,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601052673,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 75,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 37,
                "Value": 74,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 76,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 27725631,
                "Value": 55489262,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 77,
                "Name": "internal.metrics.executorRunTime",
                "Update": 453,
                "Value": 869,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 78,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 393761021,
                "Value": 744850821,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 79,
                "Name": "internal.metrics.resultSize",
                "Update": 1823,
                "Value": 3646,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 80,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 25,
                "Value": 50,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 82,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 83,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 84,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 16520564,
                "Value": 31093521,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 86,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 87,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 88,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1514647,
                "Value": 2988355,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 89,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 90,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1489563,
                "Value": 3015748,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 91,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 92,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 217023,
                "Value": 434936,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 98,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4636889,
                "Value": 9261719,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 99,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 181259,
                "Value": 363240,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 37,
        "Executor Deserialize CPU Time": 27725631,
        "Executor Run Time": 453,
        "Executor CPU Time": 393761021,
        "Peak Execution Memory": 16520564,
        "Result Size": 1823,
        "JVM GC Time": 25,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1514647,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1489563,
            "Total Records Read": 217023
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4636889,
            "Records Written": 181259
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 3,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 18,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"14\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    17
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 17,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"13\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601041000\",\"name\":\"foreachRDD @ 17:37:21\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    16
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            2
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601052144,
        "Completion Time": 1680601052675,
        "Accumulables": [
            {
                "ID": 75,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 74,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 76,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 55489262,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 77,
                "Name": "internal.metrics.executorRunTime",
                "Value": 869,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 78,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 744850821,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 79,
                "Name": "internal.metrics.resultSize",
                "Value": 3646,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 80,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 50,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 82,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 83,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 84,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 31093521,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 86,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 87,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 88,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Value": 2988355,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 89,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 90,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Value": 3015748,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 91,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 92,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Value": 434936,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 98,
                "Name": "internal.metrics.output.bytesWritten",
                "Value": 9261719,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 99,
                "Name": "internal.metrics.output.recordsWritten",
                "Value": 363240,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerJobEnd",
    "Job ID": 1,
    "Completion Time": 1680601052676,
    "Job Result": {
        "Result": "JobSucceeded"
    }
}
{
    "Event": "SparkListenerUnpersistRDD",
    "RDD ID": 0
}
{
    "Event": "SparkListenerJobStart",
    "Job ID": 2,
    "Submission Time": 1680601052796,
    "Stage Infos": [
        {
            "Stage ID": 4,
            "Stage Attempt ID": 0,
            "Stage Name": "map at main.scala:46",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 22,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"21\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
                    "Callsite": "map at main.scala:46",
                    "Parent IDs": [
                        21
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 21,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"20\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
                    "Callsite": "flatMap at main.scala:41",
                    "Parent IDs": [
                        6
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 6,
                    "Name": "KafkaRDD",
                    "Scope": "{\"id\":\"0_1680601042000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:22\"}",
                    "Callsite": "createDirectStream at main.scala:31",
                    "Parent IDs": [],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [],
            "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
            "Accumulables": [],
            "Resource Profile Id": 0
        },
        {
            "Stage ID": 5,
            "Stage Attempt ID": 0,
            "Stage Name": "runJob at SparkHadoopWriter.scala:83",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 24,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"23\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
                    "Callsite": "saveAsTextFile at main.scala:48",
                    "Parent IDs": [
                        23
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 23,
                    "Name": "ShuffledRDD",
                    "Scope": "{\"id\":\"22\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
                    "Callsite": "reduceByKey at main.scala:46",
                    "Parent IDs": [
                        22
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [
                4
            ],
            "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
            "Accumulables": [],
            "Resource Profile Id": 0
        }
    ],
    "Stage IDs": [
        4,
        5
    ],
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"23\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
        "spark.job.interruptOnCancel": "false",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601042000\">[output operation 0, batch time 17:37:22]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601042000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 4,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 22,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"21\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    21
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 21,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"20\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    6
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 6,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601042000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:22\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601052800,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"23\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601042000\">[output operation 0, batch time 17:37:22]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601042000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 4,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 8,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601052812,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 4,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 9,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601052813,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 4,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 9,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601052813,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601054257,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 100,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 17,
                "Value": 17,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 101,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 9125674,
                "Value": 9125674,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 102,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1415,
                "Value": 1415,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 103,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1384592630,
                "Value": 1384592630,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 104,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 1295,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 105,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 27,
                "Value": 27,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 107,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 108,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 109,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 31162045,
                "Value": 31162045,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 118,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 3068744,
                "Value": 3068744,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 119,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 234644,
                "Value": 234644,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 120,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 4575348,
                "Value": 4575348,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 17,
        "Executor Deserialize CPU Time": 9125674,
        "Executor Run Time": 1415,
        "Executor CPU Time": 1384592630,
        "Peak Execution Memory": 31162045,
        "Result Size": 1295,
        "JVM GC Time": 27,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 3068744,
            "Shuffle Write Time": 4575348,
            "Shuffle Records Written": 234644
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 4,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 8,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601052812,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601054531,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 100,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 22,
                "Value": 39,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 101,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 14569748,
                "Value": 23695422,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 102,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1686,
                "Value": 3101,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 103,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1530226053,
                "Value": 2914818683,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 104,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 105,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 41,
                "Value": 68,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 107,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 108,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 109,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 25867020,
                "Value": 57029065,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 118,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 3154947,
                "Value": 6223691,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 119,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 234320,
                "Value": 468964,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 120,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 4372917,
                "Value": 8948265,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 22,
        "Executor Deserialize CPU Time": 14569748,
        "Executor Run Time": 1686,
        "Executor CPU Time": 1530226053,
        "Peak Execution Memory": 25867020,
        "Result Size": 1295,
        "JVM GC Time": 41,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 3154947,
            "Shuffle Write Time": 4372917,
            "Shuffle Records Written": 234320
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 4,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 22,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"21\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    21
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 21,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"20\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    6
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 6,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601042000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:22\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601052800,
        "Completion Time": 1680601054533,
        "Accumulables": [
            {
                "ID": 100,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 39,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 101,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 23695422,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 102,
                "Name": "internal.metrics.executorRunTime",
                "Value": 3101,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 103,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 2914818683,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 104,
                "Name": "internal.metrics.resultSize",
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 105,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 68,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 107,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 108,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 109,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 57029065,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 118,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Value": 6223691,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 119,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Value": 468964,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 120,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Value": 8948265,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 5,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 24,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"23\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    23
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 23,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"22\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    22
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            4
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601054536,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"23\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601042000\">[output operation 0, batch time 17:37:22]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601042000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 5,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 10,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601054554,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 5,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 11,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601054555,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 5,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 11,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601054555,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601055009,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 125,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 33,
                "Value": 33,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 126,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 25758322,
                "Value": 25758322,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 127,
                "Name": "internal.metrics.executorRunTime",
                "Update": 410,
                "Value": 410,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 128,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 376596740,
                "Value": 376596740,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 129,
                "Name": "internal.metrics.resultSize",
                "Update": 1780,
                "Value": 1780,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 132,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 133,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 134,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 19737637,
                "Value": 19737637,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 136,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 137,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 138,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1528294,
                "Value": 1528294,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 139,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 140,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1582022,
                "Value": 1582022,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 141,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 142,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 234240,
                "Value": 234240,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 148,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 6389193,
                "Value": 6389193,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 149,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 198468,
                "Value": 198468,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 33,
        "Executor Deserialize CPU Time": 25758322,
        "Executor Run Time": 410,
        "Executor CPU Time": 376596740,
        "Peak Execution Memory": 19737637,
        "Result Size": 1780,
        "JVM GC Time": 0,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1528294,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1582022,
            "Total Records Read": 234240
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 6389193,
            "Records Written": 198468
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 5,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 10,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601054554,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601055102,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 125,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 28,
                "Value": 61,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 126,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 20557872,
                "Value": 46316194,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 127,
                "Name": "internal.metrics.executorRunTime",
                "Update": 506,
                "Value": 916,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 128,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 435920038,
                "Value": 812516778,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 129,
                "Name": "internal.metrics.resultSize",
                "Update": 1823,
                "Value": 3603,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 130,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 30,
                "Value": 30,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 132,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 133,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 134,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 21533489,
                "Value": 41271126,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 136,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 137,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 138,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1572925,
                "Value": 3101219,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 139,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 140,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1540450,
                "Value": 3122472,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 141,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 142,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 234724,
                "Value": 468964,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 148,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 6376165,
                "Value": 12765358,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 149,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 198563,
                "Value": 397031,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 28,
        "Executor Deserialize CPU Time": 20557872,
        "Executor Run Time": 506,
        "Executor CPU Time": 435920038,
        "Peak Execution Memory": 21533489,
        "Result Size": 1823,
        "JVM GC Time": 30,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1572925,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1540450,
            "Total Records Read": 234724
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 6376165,
            "Records Written": 198563
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 5,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 24,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"23\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    23
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 23,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"22\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601042000\",\"name\":\"foreachRDD @ 17:37:22\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    22
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            4
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601054536,
        "Completion Time": 1680601055104,
        "Accumulables": [
            {
                "ID": 125,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 61,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 126,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 46316194,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 127,
                "Name": "internal.metrics.executorRunTime",
                "Value": 916,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 128,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 812516778,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 129,
                "Name": "internal.metrics.resultSize",
                "Value": 3603,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 130,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 30,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 132,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 133,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 134,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 41271126,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 136,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 137,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 138,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Value": 3101219,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 139,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 140,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Value": 3122472,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 141,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 142,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Value": 468964,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 148,
                "Name": "internal.metrics.output.bytesWritten",
                "Value": 12765358,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 149,
                "Name": "internal.metrics.output.recordsWritten",
                "Value": 397031,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerJobEnd",
    "Job ID": 2,
    "Completion Time": 1680601055104,
    "Job Result": {
        "Result": "JobSucceeded"
    }
}
{
    "Event": "SparkListenerUnpersistRDD",
    "RDD ID": 5
}
{
    "Event": "SparkListenerJobStart",
    "Job ID": 3,
    "Submission Time": 1680601055223,
    "Stage Infos": [
        {
            "Stage ID": 6,
            "Stage Attempt ID": 0,
            "Stage Name": "map at main.scala:46",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 29,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"30\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
                    "Callsite": "map at main.scala:46",
                    "Parent IDs": [
                        28
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 28,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"29\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
                    "Callsite": "flatMap at main.scala:41",
                    "Parent IDs": [
                        7
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 7,
                    "Name": "KafkaRDD",
                    "Scope": "{\"id\":\"0_1680601043000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:23\"}",
                    "Callsite": "createDirectStream at main.scala:31",
                    "Parent IDs": [],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [],
            "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
            "Accumulables": [],
            "Resource Profile Id": 0
        },
        {
            "Stage ID": 7,
            "Stage Attempt ID": 0,
            "Stage Name": "runJob at SparkHadoopWriter.scala:83",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 31,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"32\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
                    "Callsite": "saveAsTextFile at main.scala:48",
                    "Parent IDs": [
                        30
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 30,
                    "Name": "ShuffledRDD",
                    "Scope": "{\"id\":\"31\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
                    "Callsite": "reduceByKey at main.scala:46",
                    "Parent IDs": [
                        29
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [
                6
            ],
            "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
            "Accumulables": [],
            "Resource Profile Id": 0
        }
    ],
    "Stage IDs": [
        6,
        7
    ],
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"32\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
        "spark.job.interruptOnCancel": "false",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601043000\">[output operation 0, batch time 17:37:23]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601043000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 6,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 29,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"30\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    28
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 28,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"29\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    7
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 7,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601043000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:23\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601055225,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"32\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601043000\">[output operation 0, batch time 17:37:23]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601043000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 6,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 12,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601055234,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 6,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 13,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601055235,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 6,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 12,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601055234,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601056652,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 150,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 19,
                "Value": 19,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 151,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 12751403,
                "Value": 12751403,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 152,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1387,
                "Value": 1387,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 153,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1360124851,
                "Value": 1360124851,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 154,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 1295,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 155,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 18,
                "Value": 18,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 157,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 158,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 159,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 26666110,
                "Value": 26666110,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 168,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 2629665,
                "Value": 2629665,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 169,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 232832,
                "Value": 232832,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 170,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 3385590,
                "Value": 3385590,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 706391552,
        "JVMOffHeapMemory": 97122816,
        "OnHeapExecutionMemory": 16401636,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 475338,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 16876974,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 68180829,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 14,
        "MinorGCTime": 210,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 210
    },
    "Task Metrics": {
        "Executor Deserialize Time": 19,
        "Executor Deserialize CPU Time": 12751403,
        "Executor Run Time": 1387,
        "Executor CPU Time": 1360124851,
        "Peak Execution Memory": 26666110,
        "Result Size": 1295,
        "JVM GC Time": 18,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 2629665,
            "Shuffle Write Time": 3385590,
            "Shuffle Records Written": 232832
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 6,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 13,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601055235,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601056873,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 150,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 15,
                "Value": 34,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 151,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 8667452,
                "Value": 21418855,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 152,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1614,
                "Value": 3001,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 153,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1469821480,
                "Value": 2829946331,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 154,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 155,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 23,
                "Value": 41,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 157,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 158,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 159,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 24250918,
                "Value": 50917028,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 168,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 2625267,
                "Value": 5254932,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 169,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 233095,
                "Value": 465927,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 170,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 3188547,
                "Value": 6574137,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 15,
        "Executor Deserialize CPU Time": 8667452,
        "Executor Run Time": 1614,
        "Executor CPU Time": 1469821480,
        "Peak Execution Memory": 24250918,
        "Result Size": 1295,
        "JVM GC Time": 23,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 2625267,
            "Shuffle Write Time": 3188547,
            "Shuffle Records Written": 233095
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 6,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 29,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"30\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    28
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 28,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"29\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    7
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 7,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601043000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:23\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601055225,
        "Completion Time": 1680601056875,
        "Accumulables": [
            {
                "ID": 150,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 34,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 151,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 21418855,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 152,
                "Name": "internal.metrics.executorRunTime",
                "Value": 3001,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 153,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 2829946331,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 154,
                "Name": "internal.metrics.resultSize",
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 155,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 41,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 157,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 158,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 159,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 50917028,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 168,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Value": 5254932,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 169,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Value": 465927,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 170,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Value": 6574137,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 7,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 31,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"32\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    30
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 30,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"31\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    29
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            6
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601056878,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"32\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601043000\">[output operation 0, batch time 17:37:23]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601043000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 7,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 14,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601056902,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 7,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 15,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601056903,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 7,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 15,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601056903,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601057310,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 175,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 26,
                "Value": 26,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 176,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 17936667,
                "Value": 17936667,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 177,
                "Name": "internal.metrics.executorRunTime",
                "Update": 370,
                "Value": 370,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 178,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 333322350,
                "Value": 333322350,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 179,
                "Name": "internal.metrics.resultSize",
                "Update": 1780,
                "Value": 1780,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 182,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 183,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 184,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 15243643,
                "Value": 15243643,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 186,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 187,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 188,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1307892,
                "Value": 1307892,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 189,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 190,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1304678,
                "Value": 1304678,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 191,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 192,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 231593,
                "Value": 231593,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 198,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4814173,
                "Value": 4814173,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 199,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 196276,
                "Value": 196276,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 26,
        "Executor Deserialize CPU Time": 17936667,
        "Executor Run Time": 370,
        "Executor CPU Time": 333322350,
        "Peak Execution Memory": 15243643,
        "Result Size": 1780,
        "JVM GC Time": 0,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1307892,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1304678,
            "Total Records Read": 231593
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4814173,
            "Records Written": 196276
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 7,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 14,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601056902,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601057340,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 175,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 36,
                "Value": 62,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 176,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 27846222,
                "Value": 45782889,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 177,
                "Name": "internal.metrics.executorRunTime",
                "Update": 389,
                "Value": 759,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 178,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 323032978,
                "Value": 656355328,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 179,
                "Name": "internal.metrics.resultSize",
                "Update": 1823,
                "Value": 3603,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 180,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 31,
                "Value": 31,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 182,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 183,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 184,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 15209214,
                "Value": 30452857,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 186,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 187,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 188,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1324987,
                "Value": 2632879,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 189,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 190,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1317375,
                "Value": 2622053,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 191,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 192,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 234334,
                "Value": 465927,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 198,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4862673,
                "Value": 9676846,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 199,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 198381,
                "Value": 394657,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 36,
        "Executor Deserialize CPU Time": 27846222,
        "Executor Run Time": 389,
        "Executor CPU Time": 323032978,
        "Peak Execution Memory": 15209214,
        "Result Size": 1823,
        "JVM GC Time": 31,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1324987,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1317375,
            "Total Records Read": 234334
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4862673,
            "Records Written": 198381
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 7,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 31,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"32\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    30
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 30,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"31\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601043000\",\"name\":\"foreachRDD @ 17:37:23\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    29
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            6
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601056878,
        "Completion Time": 1680601057341,
        "Accumulables": [
            {
                "ID": 175,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 62,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 176,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 45782889,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 177,
                "Name": "internal.metrics.executorRunTime",
                "Value": 759,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 178,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 656355328,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 179,
                "Name": "internal.metrics.resultSize",
                "Value": 3603,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 180,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 31,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 182,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 183,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 184,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 30452857,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 186,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 187,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 188,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Value": 2632879,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 189,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 190,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Value": 2622053,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 191,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 192,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Value": 465927,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 198,
                "Name": "internal.metrics.output.bytesWritten",
                "Value": 9676846,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 199,
                "Name": "internal.metrics.output.recordsWritten",
                "Value": 394657,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerJobEnd",
    "Job ID": 3,
    "Completion Time": 1680601057342,
    "Job Result": {
        "Result": "JobSucceeded"
    }
}
{
    "Event": "SparkListenerUnpersistRDD",
    "RDD ID": 6
}
{
    "Event": "SparkListenerJobStart",
    "Job ID": 4,
    "Submission Time": 1680601057453,
    "Stage Infos": [
        {
            "Stage ID": 8,
            "Stage Attempt ID": 0,
            "Stage Name": "map at main.scala:46",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 35,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"39\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
                    "Callsite": "map at main.scala:46",
                    "Parent IDs": [
                        34
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 34,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"38\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
                    "Callsite": "flatMap at main.scala:41",
                    "Parent IDs": [
                        8
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 8,
                    "Name": "KafkaRDD",
                    "Scope": "{\"id\":\"0_1680601044000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:24\"}",
                    "Callsite": "createDirectStream at main.scala:31",
                    "Parent IDs": [],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [],
            "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
            "Accumulables": [],
            "Resource Profile Id": 0
        },
        {
            "Stage ID": 9,
            "Stage Attempt ID": 0,
            "Stage Name": "runJob at SparkHadoopWriter.scala:83",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 37,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"41\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
                    "Callsite": "saveAsTextFile at main.scala:48",
                    "Parent IDs": [
                        36
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 36,
                    "Name": "ShuffledRDD",
                    "Scope": "{\"id\":\"40\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
                    "Callsite": "reduceByKey at main.scala:46",
                    "Parent IDs": [
                        35
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [
                8
            ],
            "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
            "Accumulables": [],
            "Resource Profile Id": 0
        }
    ],
    "Stage IDs": [
        8,
        9
    ],
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"41\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
        "spark.job.interruptOnCancel": "false",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601044000\">[output operation 0, batch time 17:37:24]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601044000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 8,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 35,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"39\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    34
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 34,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"38\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    8
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 8,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601044000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:24\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601057455,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"41\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601044000\">[output operation 0, batch time 17:37:24]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601044000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 8,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 16,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601057464,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 8,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 17,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601057465,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 8,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 16,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601057464,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601059052,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 200,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 18,
                "Value": 18,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 201,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 11370107,
                "Value": 11370107,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 202,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1559,
                "Value": 1559,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 203,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1410545866,
                "Value": 1410545866,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 204,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 1295,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 205,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 16,
                "Value": 16,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 207,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 208,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 209,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 25953417,
                "Value": 25953417,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 218,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 3071528,
                "Value": 3071528,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 219,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 226896,
                "Value": 226896,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 220,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 3474928,
                "Value": 3474928,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 18,
        "Executor Deserialize CPU Time": 11370107,
        "Executor Run Time": 1559,
        "Executor CPU Time": 1410545866,
        "Peak Execution Memory": 25953417,
        "Result Size": 1295,
        "JVM GC Time": 16,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 3071528,
            "Shuffle Write Time": 3474928,
            "Shuffle Records Written": 226896
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 8,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 17,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601057465,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601059079,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 200,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 19,
                "Value": 37,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 201,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 12542877,
                "Value": 23912984,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 202,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1584,
                "Value": 3143,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 203,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1524773529,
                "Value": 2935319395,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 204,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 205,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 52,
                "Value": 68,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 207,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 208,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 209,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 30247221,
                "Value": 56200638,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 218,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 3128316,
                "Value": 6199844,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 219,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 226720,
                "Value": 453616,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 220,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 4740335,
                "Value": 8215263,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 19,
        "Executor Deserialize CPU Time": 12542877,
        "Executor Run Time": 1584,
        "Executor CPU Time": 1524773529,
        "Peak Execution Memory": 30247221,
        "Result Size": 1295,
        "JVM GC Time": 52,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 3128316,
            "Shuffle Write Time": 4740335,
            "Shuffle Records Written": 226720
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 8,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 35,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"39\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    34
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 34,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"38\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    8
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 8,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601044000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:24\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601057455,
        "Completion Time": 1680601059081,
        "Accumulables": [
            {
                "ID": 200,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 37,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 201,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 23912984,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 202,
                "Name": "internal.metrics.executorRunTime",
                "Value": 3143,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 203,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 2935319395,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 204,
                "Name": "internal.metrics.resultSize",
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 205,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 68,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 207,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 208,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 209,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 56200638,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 218,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Value": 6199844,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 219,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Value": 453616,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 220,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Value": 8215263,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 9,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 37,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"41\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    36
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 36,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"40\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    35
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            8
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601059084,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"41\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601044000\">[output operation 0, batch time 17:37:24]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601044000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 9,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 18,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601059107,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 9,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 19,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601059107,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 9,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 18,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601059107,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601059555,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 225,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 19,
                "Value": 19,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 226,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 13461626,
                "Value": 13461626,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 227,
                "Name": "internal.metrics.executorRunTime",
                "Update": 419,
                "Value": 419,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 228,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 348292963,
                "Value": 348292963,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 229,
                "Name": "internal.metrics.resultSize",
                "Update": 1823,
                "Value": 1823,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 230,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 32,
                "Value": 32,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 232,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 233,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 234,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 17364892,
                "Value": 17364892,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 236,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 237,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 238,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1572456,
                "Value": 1572456,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 239,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 240,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1528375,
                "Value": 1528375,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 241,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 242,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 227604,
                "Value": 227604,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 248,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4812822,
                "Value": 4812822,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 249,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 188825,
                "Value": 188825,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 19,
        "Executor Deserialize CPU Time": 13461626,
        "Executor Run Time": 419,
        "Executor CPU Time": 348292963,
        "Peak Execution Memory": 17364892,
        "Result Size": 1823,
        "JVM GC Time": 32,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1572456,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1528375,
            "Total Records Read": 227604
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4812822,
            "Records Written": 188825
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 9,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 19,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601059107,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601059562,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 225,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 26,
                "Value": 45,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 226,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 21217706,
                "Value": 34679332,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 227,
                "Name": "internal.metrics.executorRunTime",
                "Update": 421,
                "Value": 840,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 228,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 389919357,
                "Value": 738212320,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 229,
                "Name": "internal.metrics.resultSize",
                "Update": 1780,
                "Value": 3603,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 232,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 233,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 234,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 14066832,
                "Value": 31431724,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 236,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 237,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 238,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1543153,
                "Value": 3115609,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 239,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 240,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1555860,
                "Value": 3084235,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 241,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 242,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 226012,
                "Value": 453616,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 248,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4794129,
                "Value": 9606951,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 249,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 187746,
                "Value": 376571,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 26,
        "Executor Deserialize CPU Time": 21217706,
        "Executor Run Time": 421,
        "Executor CPU Time": 389919357,
        "Peak Execution Memory": 14066832,
        "Result Size": 1780,
        "JVM GC Time": 0,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1543153,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1555860,
            "Total Records Read": 226012
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4794129,
            "Records Written": 187746
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 9,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 37,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"41\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    36
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 36,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"40\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601044000\",\"name\":\"foreachRDD @ 17:37:24\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    35
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            8
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601059084,
        "Completion Time": 1680601059564,
        "Accumulables": [
            {
                "ID": 225,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 45,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 226,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 34679332,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 227,
                "Name": "internal.metrics.executorRunTime",
                "Value": 840,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 228,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 738212320,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 229,
                "Name": "internal.metrics.resultSize",
                "Value": 3603,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 230,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 32,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 232,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 233,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 234,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 31431724,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 236,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 237,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 238,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Value": 3115609,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 239,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 240,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Value": 3084235,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 241,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 242,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Value": 453616,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 248,
                "Name": "internal.metrics.output.bytesWritten",
                "Value": 9606951,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 249,
                "Name": "internal.metrics.output.recordsWritten",
                "Value": 376571,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerJobEnd",
    "Job ID": 4,
    "Completion Time": 1680601059565,
    "Job Result": {
        "Result": "JobSucceeded"
    }
}
{
    "Event": "SparkListenerUnpersistRDD",
    "RDD ID": 7
}
{
    "Event": "SparkListenerJobStart",
    "Job ID": 5,
    "Submission Time": 1680601059655,
    "Stage Infos": [
        {
            "Stage ID": 10,
            "Stage Attempt ID": 0,
            "Stage Name": "map at main.scala:46",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 41,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"48\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
                    "Callsite": "map at main.scala:46",
                    "Parent IDs": [
                        40
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 9,
                    "Name": "KafkaRDD",
                    "Scope": "{\"id\":\"0_1680601045000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:25\"}",
                    "Callsite": "createDirectStream at main.scala:31",
                    "Parent IDs": [],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 40,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"47\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
                    "Callsite": "flatMap at main.scala:41",
                    "Parent IDs": [
                        9
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [],
            "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
            "Accumulables": [],
            "Resource Profile Id": 0
        },
        {
            "Stage ID": 11,
            "Stage Attempt ID": 0,
            "Stage Name": "runJob at SparkHadoopWriter.scala:83",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 43,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"50\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
                    "Callsite": "saveAsTextFile at main.scala:48",
                    "Parent IDs": [
                        42
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 42,
                    "Name": "ShuffledRDD",
                    "Scope": "{\"id\":\"49\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
                    "Callsite": "reduceByKey at main.scala:46",
                    "Parent IDs": [
                        41
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [
                10
            ],
            "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
            "Accumulables": [],
            "Resource Profile Id": 0
        }
    ],
    "Stage IDs": [
        10,
        11
    ],
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"50\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
        "spark.job.interruptOnCancel": "false",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601045000\">[output operation 0, batch time 17:37:25]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601045000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 10,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 41,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"48\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    40
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 9,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601045000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:25\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 40,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"47\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    9
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601059657,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"50\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601045000\">[output operation 0, batch time 17:37:25]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601045000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 10,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 20,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601059666,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 10,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 21,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601059666,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 10,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 20,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601059666,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601061142,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 250,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 16,
                "Value": 16,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 251,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 9680458,
                "Value": 9680458,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 252,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1452,
                "Value": 1452,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 253,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1428138643,
                "Value": 1428138643,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 254,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 1295,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 255,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 18,
                "Value": 18,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 257,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 258,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 259,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 25333357,
                "Value": 25333357,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 268,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 3207868,
                "Value": 3207868,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 269,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 226110,
                "Value": 226110,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 270,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 3980610,
                "Value": 3980610,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 16,
        "Executor Deserialize CPU Time": 9680458,
        "Executor Run Time": 1452,
        "Executor CPU Time": 1428138643,
        "Peak Execution Memory": 25333357,
        "Result Size": 1295,
        "JVM GC Time": 18,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 3207868,
            "Shuffle Write Time": 3980610,
            "Shuffle Records Written": 226110
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 10,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 21,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601059666,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601061448,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 250,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 14,
                "Value": 30,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 251,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 8068105,
                "Value": 17748563,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 252,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1760,
                "Value": 3212,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 253,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1594474829,
                "Value": 3022613472,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 254,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 255,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 28,
                "Value": 46,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 257,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 258,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 259,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 25088933,
                "Value": 50422290,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 268,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 3209825,
                "Value": 6417693,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 269,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 224479,
                "Value": 450589,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 270,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 4060153,
                "Value": 8040763,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 14,
        "Executor Deserialize CPU Time": 8068105,
        "Executor Run Time": 1760,
        "Executor CPU Time": 1594474829,
        "Peak Execution Memory": 25088933,
        "Result Size": 1295,
        "JVM GC Time": 28,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 3209825,
            "Shuffle Write Time": 4060153,
            "Shuffle Records Written": 224479
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 10,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 41,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"48\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    40
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 9,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601045000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:25\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 40,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"47\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    9
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601059657,
        "Completion Time": 1680601061450,
        "Accumulables": [
            {
                "ID": 250,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 30,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 251,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 17748563,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 252,
                "Name": "internal.metrics.executorRunTime",
                "Value": 3212,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 253,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 3022613472,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 254,
                "Name": "internal.metrics.resultSize",
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 255,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 46,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 257,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 258,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 259,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 50422290,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 268,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Value": 6417693,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 269,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Value": 450589,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 270,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Value": 8040763,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 11,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 43,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"50\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    42
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 42,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"49\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    41
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            10
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601061453,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"50\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601045000\">[output operation 0, batch time 17:37:25]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601045000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 11,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 22,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601061476,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 11,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 23,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601061476,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 11,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 23,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601061476,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601061871,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 275,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 30,
                "Value": 30,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 276,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 22519550,
                "Value": 22519550,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 277,
                "Name": "internal.metrics.executorRunTime",
                "Update": 355,
                "Value": 355,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 278,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 296063161,
                "Value": 296063161,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 279,
                "Name": "internal.metrics.resultSize",
                "Update": 1823,
                "Value": 1823,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 280,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 24,
                "Value": 24,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 282,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 283,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 284,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 15602728,
                "Value": 15602728,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 286,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 287,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 288,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1600213,
                "Value": 1600213,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 289,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 290,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1608432,
                "Value": 1608432,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 291,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 292,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 224593,
                "Value": 224593,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 298,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4522756,
                "Value": 4522756,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 299,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 183920,
                "Value": 183920,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 30,
        "Executor Deserialize CPU Time": 22519550,
        "Executor Run Time": 355,
        "Executor CPU Time": 296063161,
        "Peak Execution Memory": 15602728,
        "Result Size": 1823,
        "JVM GC Time": 24,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1600213,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1608432,
            "Total Records Read": 224593
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4522756,
            "Records Written": 183920
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 11,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 22,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601061476,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601061872,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 275,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 34,
                "Value": 64,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 276,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 26886448,
                "Value": 49405998,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 277,
                "Name": "internal.metrics.executorRunTime",
                "Update": 351,
                "Value": 706,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 278,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 313865897,
                "Value": 609929058,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 279,
                "Name": "internal.metrics.resultSize",
                "Update": 1780,
                "Value": 3603,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 282,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 283,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 284,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 19461120,
                "Value": 35063848,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 286,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 287,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 288,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1599436,
                "Value": 3199649,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 289,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 290,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1609612,
                "Value": 3218044,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 291,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 292,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 225996,
                "Value": 450589,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 298,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4535983,
                "Value": 9058739,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 299,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 185122,
                "Value": 369042,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 34,
        "Executor Deserialize CPU Time": 26886448,
        "Executor Run Time": 351,
        "Executor CPU Time": 313865897,
        "Peak Execution Memory": 19461120,
        "Result Size": 1780,
        "JVM GC Time": 0,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1599436,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1609612,
            "Total Records Read": 225996
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4535983,
            "Records Written": 185122
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 11,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 43,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"50\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    42
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 42,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"49\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601045000\",\"name\":\"foreachRDD @ 17:37:25\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    41
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            10
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601061453,
        "Completion Time": 1680601061873,
        "Accumulables": [
            {
                "ID": 275,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 64,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 276,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 49405998,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 277,
                "Name": "internal.metrics.executorRunTime",
                "Value": 706,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 278,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 609929058,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 279,
                "Name": "internal.metrics.resultSize",
                "Value": 3603,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 280,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 24,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 282,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 283,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 284,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 35063848,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 286,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 287,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 288,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Value": 3199649,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 289,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 290,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Value": 3218044,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 291,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 292,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Value": 450589,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 298,
                "Name": "internal.metrics.output.bytesWritten",
                "Value": 9058739,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 299,
                "Name": "internal.metrics.output.recordsWritten",
                "Value": 369042,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerJobEnd",
    "Job ID": 5,
    "Completion Time": 1680601061873,
    "Job Result": {
        "Result": "JobSucceeded"
    }
}
{
    "Event": "SparkListenerUnpersistRDD",
    "RDD ID": 8
}
{
    "Event": "SparkListenerJobStart",
    "Job ID": 6,
    "Submission Time": 1680601061978,
    "Stage Infos": [
        {
            "Stage ID": 12,
            "Stage Attempt ID": 0,
            "Stage Name": "map at main.scala:46",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 47,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"57\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
                    "Callsite": "map at main.scala:46",
                    "Parent IDs": [
                        46
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 10,
                    "Name": "KafkaRDD",
                    "Scope": "{\"id\":\"0_1680601046000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:26\"}",
                    "Callsite": "createDirectStream at main.scala:31",
                    "Parent IDs": [],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 46,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"56\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
                    "Callsite": "flatMap at main.scala:41",
                    "Parent IDs": [
                        10
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [],
            "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
            "Accumulables": [],
            "Resource Profile Id": 0
        },
        {
            "Stage ID": 13,
            "Stage Attempt ID": 0,
            "Stage Name": "runJob at SparkHadoopWriter.scala:83",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 49,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"59\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
                    "Callsite": "saveAsTextFile at main.scala:48",
                    "Parent IDs": [
                        48
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 48,
                    "Name": "ShuffledRDD",
                    "Scope": "{\"id\":\"58\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
                    "Callsite": "reduceByKey at main.scala:46",
                    "Parent IDs": [
                        47
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [
                12
            ],
            "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
            "Accumulables": [],
            "Resource Profile Id": 0
        }
    ],
    "Stage IDs": [
        12,
        13
    ],
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"59\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
        "spark.job.interruptOnCancel": "false",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601046000\">[output operation 0, batch time 17:37:26]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601046000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 12,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 47,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"57\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    46
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 10,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601046000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:26\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 46,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"56\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    10
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601061980,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"59\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601046000\">[output operation 0, batch time 17:37:26]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601046000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 12,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 24,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601061988,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 12,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 25,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601061988,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 12,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 24,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601061988,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601063520,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 300,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 16,
                "Value": 16,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 301,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 10492869,
                "Value": 10492869,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 302,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1507,
                "Value": 1507,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 303,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1471672738,
                "Value": 1471672738,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 304,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 1295,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 305,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 30,
                "Value": 30,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 307,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 308,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 309,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 24418619,
                "Value": 24418619,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 318,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 3228964,
                "Value": 3228964,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 319,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 245253,
                "Value": 245253,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 320,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 4247248,
                "Value": 4247248,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 16,
        "Executor Deserialize CPU Time": 10492869,
        "Executor Run Time": 1507,
        "Executor CPU Time": 1471672738,
        "Peak Execution Memory": 24418619,
        "Result Size": 1295,
        "JVM GC Time": 30,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 3228964,
            "Shuffle Write Time": 4247248,
            "Shuffle Records Written": 245253
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 12,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 25,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601061988,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601063925,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 300,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 19,
                "Value": 35,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 301,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 12859166,
                "Value": 23352035,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 302,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1909,
                "Value": 3416,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 303,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1716208743,
                "Value": 3187881481,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 304,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 305,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 58,
                "Value": 88,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 307,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 308,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 309,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 31999059,
                "Value": 56417678,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 318,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 3271934,
                "Value": 6500898,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 319,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 243177,
                "Value": 488430,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 320,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 3675612,
                "Value": 7922860,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 19,
        "Executor Deserialize CPU Time": 12859166,
        "Executor Run Time": 1909,
        "Executor CPU Time": 1716208743,
        "Peak Execution Memory": 31999059,
        "Result Size": 1295,
        "JVM GC Time": 58,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 3271934,
            "Shuffle Write Time": 3675612,
            "Shuffle Records Written": 243177
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 12,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 47,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"57\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    46
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 10,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601046000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:26\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 46,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"56\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    10
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601061980,
        "Completion Time": 1680601063926,
        "Accumulables": [
            {
                "ID": 300,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 35,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 301,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 23352035,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 302,
                "Name": "internal.metrics.executorRunTime",
                "Value": 3416,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 303,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 3187881481,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 304,
                "Name": "internal.metrics.resultSize",
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 305,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 88,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 307,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 308,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 309,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 56417678,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 318,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Value": 6500898,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 319,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Value": 488430,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 320,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Value": 7922860,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 13,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 49,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"59\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    48
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 48,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"58\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    47
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            12
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601063929,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"59\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601046000\">[output operation 0, batch time 17:37:26]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601046000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 13,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 26,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601063955,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 13,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 27,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601063955,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 13,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 26,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601063955,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601064366,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 325,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 32,
                "Value": 32,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 326,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 21254921,
                "Value": 21254921,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 327,
                "Name": "internal.metrics.executorRunTime",
                "Update": 371,
                "Value": 371,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 328,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 329853236,
                "Value": 329853236,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 329,
                "Name": "internal.metrics.resultSize",
                "Update": 1780,
                "Value": 1780,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 332,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 333,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 334,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 18371145,
                "Value": 18371145,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 336,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 337,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 338,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1611272,
                "Value": 1611272,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 339,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 340,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1627124,
                "Value": 1627124,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 341,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 342,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 244008,
                "Value": 244008,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 348,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4411518,
                "Value": 4411518,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 349,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 198174,
                "Value": 198174,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 32,
        "Executor Deserialize CPU Time": 21254921,
        "Executor Run Time": 371,
        "Executor CPU Time": 329853236,
        "Peak Execution Memory": 18371145,
        "Result Size": 1780,
        "JVM GC Time": 0,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1611272,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1627124,
            "Total Records Read": 244008
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4411518,
            "Records Written": 198174
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 13,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 27,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601063955,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601064385,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 325,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 31,
                "Value": 63,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 326,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 22668951,
                "Value": 43923872,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 327,
                "Name": "internal.metrics.executorRunTime",
                "Update": 390,
                "Value": 761,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 328,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 327765045,
                "Value": 657618281,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 329,
                "Name": "internal.metrics.resultSize",
                "Update": 1823,
                "Value": 3603,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 330,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 23,
                "Value": 23,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 332,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 333,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 334,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 15854272,
                "Value": 34225417,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 336,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 337,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 338,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1644810,
                "Value": 3256082,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 339,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 340,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1617692,
                "Value": 3244816,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 341,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 342,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 244422,
                "Value": 488430,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 348,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4441087,
                "Value": 8852605,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 349,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 198580,
                "Value": 396754,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 31,
        "Executor Deserialize CPU Time": 22668951,
        "Executor Run Time": 390,
        "Executor CPU Time": 327765045,
        "Peak Execution Memory": 15854272,
        "Result Size": 1823,
        "JVM GC Time": 23,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1644810,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1617692,
            "Total Records Read": 244422
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4441087,
            "Records Written": 198580
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 13,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 49,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"59\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    48
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 48,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"58\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601046000\",\"name\":\"foreachRDD @ 17:37:26\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    47
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            12
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601063929,
        "Completion Time": 1680601064386,
        "Accumulables": [
            {
                "ID": 325,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 63,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 326,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 43923872,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 327,
                "Name": "internal.metrics.executorRunTime",
                "Value": 761,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 328,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 657618281,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 329,
                "Name": "internal.metrics.resultSize",
                "Value": 3603,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 330,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 23,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 332,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 333,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 334,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 34225417,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 336,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 337,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 338,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Value": 3256082,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 339,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 340,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Value": 3244816,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 341,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 342,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Value": 488430,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 348,
                "Name": "internal.metrics.output.bytesWritten",
                "Value": 8852605,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 349,
                "Name": "internal.metrics.output.recordsWritten",
                "Value": 396754,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerJobEnd",
    "Job ID": 6,
    "Completion Time": 1680601064387,
    "Job Result": {
        "Result": "JobSucceeded"
    }
}
{
    "Event": "SparkListenerUnpersistRDD",
    "RDD ID": 9
}
{
    "Event": "SparkListenerJobStart",
    "Job ID": 7,
    "Submission Time": 1680601064501,
    "Stage Infos": [
        {
            "Stage ID": 14,
            "Stage Attempt ID": 0,
            "Stage Name": "map at main.scala:46",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 54,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"66\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
                    "Callsite": "map at main.scala:46",
                    "Parent IDs": [
                        53
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 53,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"65\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
                    "Callsite": "flatMap at main.scala:41",
                    "Parent IDs": [
                        11
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 11,
                    "Name": "KafkaRDD",
                    "Scope": "{\"id\":\"0_1680601047000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:27\"}",
                    "Callsite": "createDirectStream at main.scala:31",
                    "Parent IDs": [],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [],
            "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
            "Accumulables": [],
            "Resource Profile Id": 0
        },
        {
            "Stage ID": 15,
            "Stage Attempt ID": 0,
            "Stage Name": "runJob at SparkHadoopWriter.scala:83",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 56,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"68\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
                    "Callsite": "saveAsTextFile at main.scala:48",
                    "Parent IDs": [
                        55
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 55,
                    "Name": "ShuffledRDD",
                    "Scope": "{\"id\":\"67\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
                    "Callsite": "reduceByKey at main.scala:46",
                    "Parent IDs": [
                        54
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [
                14
            ],
            "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
            "Accumulables": [],
            "Resource Profile Id": 0
        }
    ],
    "Stage IDs": [
        14,
        15
    ],
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"68\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
        "spark.job.interruptOnCancel": "false",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601047000\">[output operation 0, batch time 17:37:27]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601047000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 14,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 54,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"66\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    53
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 53,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"65\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    11
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 11,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601047000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:27\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601064505,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"68\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601047000\">[output operation 0, batch time 17:37:27]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601047000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 14,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 28,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601064519,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 14,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 29,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601064519,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 14,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 28,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601064519,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601066094,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 350,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 21,
                "Value": 21,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 351,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 13069864,
                "Value": 13069864,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 352,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1545,
                "Value": 1545,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 353,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1462401882,
                "Value": 1462401882,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 354,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 1295,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 355,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 61,
                "Value": 61,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 357,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 358,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 359,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 25953739,
                "Value": 25953739,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 368,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 3305353,
                "Value": 3305353,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 369,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 250771,
                "Value": 250771,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 370,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 4091721,
                "Value": 4091721,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 309854208,
        "JVMOffHeapMemory": 99357632,
        "OnHeapExecutionMemory": 38543984,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 1095008,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 39638992,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 68180830,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 24,
        "MinorGCTime": 466,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 466
    },
    "Task Metrics": {
        "Executor Deserialize Time": 21,
        "Executor Deserialize CPU Time": 13069864,
        "Executor Run Time": 1545,
        "Executor CPU Time": 1462401882,
        "Peak Execution Memory": 25953739,
        "Result Size": 1295,
        "JVM GC Time": 61,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 3305353,
            "Shuffle Write Time": 4091721,
            "Shuffle Records Written": 250771
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 14,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 29,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601064519,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601066506,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 350,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 19,
                "Value": 40,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 351,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 12951731,
                "Value": 26021595,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 352,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1958,
                "Value": 3503,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 353,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1734277956,
                "Value": 3196679838,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 354,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 355,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 73,
                "Value": 134,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 357,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 358,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 359,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 31288035,
                "Value": 57241774,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 368,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 3245913,
                "Value": 6551266,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 369,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 249799,
                "Value": 500570,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 370,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 3955200,
                "Value": 8046921,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 794279936,
        "JVMOffHeapMemory": 99436128,
        "OnHeapExecutionMemory": 15729816,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 1095008,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 16824824,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 68176882,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 22,
        "MinorGCTime": 415,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 415
    },
    "Task Metrics": {
        "Executor Deserialize Time": 19,
        "Executor Deserialize CPU Time": 12951731,
        "Executor Run Time": 1958,
        "Executor CPU Time": 1734277956,
        "Peak Execution Memory": 31288035,
        "Result Size": 1295,
        "JVM GC Time": 73,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 3245913,
            "Shuffle Write Time": 3955200,
            "Shuffle Records Written": 249799
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 14,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 54,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"66\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    53
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 53,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"65\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    11
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 11,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601047000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:27\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601064505,
        "Completion Time": 1680601066507,
        "Accumulables": [
            {
                "ID": 350,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 40,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 351,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 26021595,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 352,
                "Name": "internal.metrics.executorRunTime",
                "Value": 3503,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 353,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 3196679838,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 354,
                "Name": "internal.metrics.resultSize",
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 355,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 134,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 357,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 358,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 359,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 57241774,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 368,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Value": 6551266,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 369,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Value": 500570,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 370,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Value": 8046921,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 15,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 56,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"68\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    55
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 55,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"67\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    54
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            14
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601066511,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"68\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601047000\">[output operation 0, batch time 17:37:27]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601047000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 15,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 30,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601066539,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 15,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 31,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601066539,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 15,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 31,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601066539,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601066949,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 375,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 27,
                "Value": 27,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 376,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 19111587,
                "Value": 19111587,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 377,
                "Name": "internal.metrics.executorRunTime",
                "Update": 373,
                "Value": 373,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 378,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 327050572,
                "Value": 327050572,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 379,
                "Name": "internal.metrics.resultSize",
                "Update": 1823,
                "Value": 1823,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 380,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 13,
                "Value": 13,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 382,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 383,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 384,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 19647366,
                "Value": 19647366,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 386,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 387,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 388,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1649502,
                "Value": 1649502,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 389,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 390,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1619585,
                "Value": 1619585,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 391,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 392,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 249765,
                "Value": 249765,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 398,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4427292,
                "Value": 4427292,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 399,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 204298,
                "Value": 204298,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 27,
        "Executor Deserialize CPU Time": 19111587,
        "Executor Run Time": 373,
        "Executor CPU Time": 327050572,
        "Peak Execution Memory": 19647366,
        "Result Size": 1823,
        "JVM GC Time": 13,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1649502,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1619585,
            "Total Records Read": 249765
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4427292,
            "Records Written": 204298
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 15,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 30,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601066539,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601066949,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 375,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 28,
                "Value": 55,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 376,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 19695471,
                "Value": 38807058,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 377,
                "Name": "internal.metrics.executorRunTime",
                "Update": 371,
                "Value": 744,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 378,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 335460387,
                "Value": 662510959,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 379,
                "Name": "internal.metrics.resultSize",
                "Update": 1780,
                "Value": 3603,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 382,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 383,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 384,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 16439441,
                "Value": 36086807,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 386,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 387,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 388,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1626328,
                "Value": 3275830,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 389,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 390,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1655851,
                "Value": 3275436,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 391,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 392,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 250805,
                "Value": 500570,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 398,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4442452,
                "Value": 8869744,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 399,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 204527,
                "Value": 408825,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 28,
        "Executor Deserialize CPU Time": 19695471,
        "Executor Run Time": 371,
        "Executor CPU Time": 335460387,
        "Peak Execution Memory": 16439441,
        "Result Size": 1780,
        "JVM GC Time": 0,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1626328,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1655851,
            "Total Records Read": 250805
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4442452,
            "Records Written": 204527
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 15,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 56,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"68\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    55
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 55,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"67\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601047000\",\"name\":\"foreachRDD @ 17:37:27\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    54
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            14
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601066511,
        "Completion Time": 1680601066951,
        "Accumulables": [
            {
                "ID": 375,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 55,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 376,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 38807058,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 377,
                "Name": "internal.metrics.executorRunTime",
                "Value": 744,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 378,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 662510959,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 379,
                "Name": "internal.metrics.resultSize",
                "Value": 3603,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 380,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 13,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 382,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 383,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 384,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 36086807,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 386,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 387,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 388,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Value": 3275830,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 389,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 390,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Value": 3275436,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 391,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 392,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Value": 500570,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 398,
                "Name": "internal.metrics.output.bytesWritten",
                "Value": 8869744,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 399,
                "Name": "internal.metrics.output.recordsWritten",
                "Value": 408825,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerJobEnd",
    "Job ID": 7,
    "Completion Time": 1680601066951,
    "Job Result": {
        "Result": "JobSucceeded"
    }
}
{
    "Event": "SparkListenerUnpersistRDD",
    "RDD ID": 10
}
{
    "Event": "SparkListenerJobStart",
    "Job ID": 8,
    "Submission Time": 1680601067052,
    "Stage Infos": [
        {
            "Stage ID": 16,
            "Stage Attempt ID": 0,
            "Stage Name": "map at main.scala:46",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 60,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"75\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
                    "Callsite": "map at main.scala:46",
                    "Parent IDs": [
                        59
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 59,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"74\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
                    "Callsite": "flatMap at main.scala:41",
                    "Parent IDs": [
                        12
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 12,
                    "Name": "KafkaRDD",
                    "Scope": "{\"id\":\"0_1680601048000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:28\"}",
                    "Callsite": "createDirectStream at main.scala:31",
                    "Parent IDs": [],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [],
            "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
            "Accumulables": [],
            "Resource Profile Id": 0
        },
        {
            "Stage ID": 17,
            "Stage Attempt ID": 0,
            "Stage Name": "runJob at SparkHadoopWriter.scala:83",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 62,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"77\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
                    "Callsite": "saveAsTextFile at main.scala:48",
                    "Parent IDs": [
                        61
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 61,
                    "Name": "ShuffledRDD",
                    "Scope": "{\"id\":\"76\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
                    "Callsite": "reduceByKey at main.scala:46",
                    "Parent IDs": [
                        60
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [
                16
            ],
            "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
            "Accumulables": [],
            "Resource Profile Id": 0
        }
    ],
    "Stage IDs": [
        16,
        17
    ],
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"77\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
        "spark.job.interruptOnCancel": "false",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601048000\">[output operation 0, batch time 17:37:28]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601048000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 16,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 60,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"75\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    59
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 59,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"74\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    12
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 12,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601048000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:28\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601067055,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"77\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601048000\">[output operation 0, batch time 17:37:28]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601048000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 16,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 32,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601067068,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 16,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 33,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601067069,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 16,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 32,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601067068,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601068815,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 400,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 18,
                "Value": 18,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 401,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 11395645,
                "Value": 11395645,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 402,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1719,
                "Value": 1719,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 403,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1661505295,
                "Value": 1661505295,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 404,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 1295,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 405,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 50,
                "Value": 50,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 407,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 408,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 409,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 29014800,
                "Value": 29014800,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 418,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 3336370,
                "Value": 3336370,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 419,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 258392,
                "Value": 258392,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 420,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 4054269,
                "Value": 4054269,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 18,
        "Executor Deserialize CPU Time": 11395645,
        "Executor Run Time": 1719,
        "Executor CPU Time": 1661505295,
        "Peak Execution Memory": 29014800,
        "Result Size": 1295,
        "JVM GC Time": 50,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 3336370,
            "Shuffle Write Time": 4054269,
            "Shuffle Records Written": 258392
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 16,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 33,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601067069,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601068939,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 400,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 19,
                "Value": 37,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 401,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 11544304,
                "Value": 22939949,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 402,
                "Name": "internal.metrics.executorRunTime",
                "Update": 1843,
                "Value": 3562,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 403,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 1681345124,
                "Value": 3342850419,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 404,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 405,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 15,
                "Value": 65,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 407,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 408,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 409,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 32286071,
                "Value": 61300871,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 418,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 3385527,
                "Value": 6721897,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 419,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 257898,
                "Value": 516290,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 420,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 3730406,
                "Value": 7784675,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 19,
        "Executor Deserialize CPU Time": 11544304,
        "Executor Run Time": 1843,
        "Executor CPU Time": 1681345124,
        "Peak Execution Memory": 32286071,
        "Result Size": 1295,
        "JVM GC Time": 15,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 3385527,
            "Shuffle Write Time": 3730406,
            "Shuffle Records Written": 257898
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 16,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 60,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"75\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    59
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 59,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"74\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    12
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 12,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601048000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:28\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601067055,
        "Completion Time": 1680601068940,
        "Accumulables": [
            {
                "ID": 400,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 37,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 401,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 22939949,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 402,
                "Name": "internal.metrics.executorRunTime",
                "Value": 3562,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 403,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 3342850419,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 404,
                "Name": "internal.metrics.resultSize",
                "Value": 2590,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 405,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 65,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 407,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 408,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 409,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 61300871,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 418,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Value": 6721897,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 419,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Value": 516290,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 420,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Value": 7784675,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 17,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 62,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"77\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    61
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 61,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"76\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    60
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            16
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601068942,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"77\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601048000\">[output operation 0, batch time 17:37:28]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601048000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 17,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 34,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601068959,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 17,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 35,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601068959,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 17,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 34,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601068959,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601069347,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 425,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 20,
                "Value": 20,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 426,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 10618945,
                "Value": 10618945,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 427,
                "Name": "internal.metrics.executorRunTime",
                "Update": 360,
                "Value": 360,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 428,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 318567794,
                "Value": 318567794,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 429,
                "Name": "internal.metrics.resultSize",
                "Update": 1780,
                "Value": 1780,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 432,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 433,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 434,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 15249963,
                "Value": 15249963,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 436,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 437,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 438,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1691499,
                "Value": 1691499,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 439,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 440,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1673014,
                "Value": 1673014,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 441,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 442,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 258861,
                "Value": 258861,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 448,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4541035,
                "Value": 4541035,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 449,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 212688,
                "Value": 212688,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 20,
        "Executor Deserialize CPU Time": 10618945,
        "Executor Run Time": 360,
        "Executor CPU Time": 318567794,
        "Peak Execution Memory": 15249963,
        "Result Size": 1780,
        "JVM GC Time": 0,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1691499,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1673014,
            "Total Records Read": 258861
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4541035,
            "Records Written": 212688
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 17,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 35,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601068959,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601069372,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 425,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 27,
                "Value": 47,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 426,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 18355595,
                "Value": 28974540,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 427,
                "Name": "internal.metrics.executorRunTime",
                "Update": 378,
                "Value": 738,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 428,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 342894239,
                "Value": 661462033,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 429,
                "Name": "internal.metrics.resultSize",
                "Update": 1780,
                "Value": 3560,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 432,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 433,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 434,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 16138890,
                "Value": 31388853,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 436,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 437,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 438,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 1663356,
                "Value": 3354855,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 439,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 440,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 1694028,
                "Value": 3367042,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 441,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 442,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 257429,
                "Value": 516290,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 448,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 4529526,
                "Value": 9070561,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 449,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 211734,
                "Value": 424422,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 27,
        "Executor Deserialize CPU Time": 18355595,
        "Executor Run Time": 378,
        "Executor CPU Time": 342894239,
        "Peak Execution Memory": 16138890,
        "Result Size": 1780,
        "JVM GC Time": 0,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 1663356,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 1694028,
            "Total Records Read": 257429
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 4529526,
            "Records Written": 211734
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 17,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 62,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"77\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    61
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 61,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"76\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601048000\",\"name\":\"foreachRDD @ 17:37:28\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    60
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            16
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601068942,
        "Completion Time": 1680601069373,
        "Accumulables": [
            {
                "ID": 425,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 47,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 426,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 28974540,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 427,
                "Name": "internal.metrics.executorRunTime",
                "Value": 738,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 428,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 661462033,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 429,
                "Name": "internal.metrics.resultSize",
                "Value": 3560,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 432,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 433,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 434,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 31388853,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 436,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 437,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 438,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Value": 3354855,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 439,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 440,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Value": 3367042,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 441,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 442,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Value": 516290,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 448,
                "Name": "internal.metrics.output.bytesWritten",
                "Value": 9070561,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 449,
                "Name": "internal.metrics.output.recordsWritten",
                "Value": 424422,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerJobEnd",
    "Job ID": 8,
    "Completion Time": 1680601069374,
    "Job Result": {
        "Result": "JobSucceeded"
    }
}
{
    "Event": "SparkListenerUnpersistRDD",
    "RDD ID": 11
}
{
    "Event": "SparkListenerJobStart",
    "Job ID": 9,
    "Submission Time": 1680601069474,
    "Stage Infos": [
        {
            "Stage ID": 18,
            "Stage Attempt ID": 0,
            "Stage Name": "map at main.scala:46",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 67,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"84\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
                    "Callsite": "map at main.scala:46",
                    "Parent IDs": [
                        66
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 13,
                    "Name": "KafkaRDD",
                    "Scope": "{\"id\":\"0_1680601049000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:29\"}",
                    "Callsite": "createDirectStream at main.scala:31",
                    "Parent IDs": [],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 66,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"83\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
                    "Callsite": "flatMap at main.scala:41",
                    "Parent IDs": [
                        13
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "DETERMINATE",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [],
            "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
            "Accumulables": [],
            "Resource Profile Id": 0
        },
        {
            "Stage ID": 19,
            "Stage Attempt ID": 0,
            "Stage Name": "runJob at SparkHadoopWriter.scala:83",
            "Number of Tasks": 2,
            "RDD Info": [
                {
                    "RDD ID": 69,
                    "Name": "MapPartitionsRDD",
                    "Scope": "{\"id\":\"86\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
                    "Callsite": "saveAsTextFile at main.scala:48",
                    "Parent IDs": [
                        68
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                },
                {
                    "RDD ID": 68,
                    "Name": "ShuffledRDD",
                    "Scope": "{\"id\":\"85\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
                    "Callsite": "reduceByKey at main.scala:46",
                    "Parent IDs": [
                        67
                    ],
                    "Storage Level": {
                        "Use Disk": false,
                        "Use Memory": false,
                        "Deserialized": false,
                        "Replication": 1
                    },
                    "Barrier": false,
                    "DeterministicLevel": "UNORDERED",
                    "Number of Partitions": 2,
                    "Number of Cached Partitions": 0,
                    "Memory Size": 0,
                    "Disk Size": 0
                }
            ],
            "Parent IDs": [
                18
            ],
            "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
            "Accumulables": [],
            "Resource Profile Id": 0
        }
    ],
    "Stage IDs": [
        18,
        19
    ],
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"86\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
        "spark.job.interruptOnCancel": "false",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601049000\">[output operation 0, batch time 17:37:29]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601049000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 18,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 67,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"84\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    66
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 13,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601049000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:29\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 66,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"83\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    13
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601069478,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"86\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601049000\">[output operation 0, batch time 17:37:29]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601049000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 18,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 36,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601069491,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 18,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 37,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601069492,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 18,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 36,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601069491,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601069847,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 450,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 16,
                "Value": 16,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 451,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 8799859,
                "Value": 8799859,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 452,
                "Name": "internal.metrics.executorRunTime",
                "Update": 331,
                "Value": 331,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 453,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 330162319,
                "Value": 330162319,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 454,
                "Name": "internal.metrics.resultSize",
                "Update": 1252,
                "Value": 1252,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 457,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 458,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 459,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 6492874,
                "Value": 6492874,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 468,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 800165,
                "Value": 800165,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 469,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 75539,
                "Value": 75539,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 470,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 1169676,
                "Value": 1169676,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 16,
        "Executor Deserialize CPU Time": 8799859,
        "Executor Run Time": 331,
        "Executor CPU Time": 330162319,
        "Peak Execution Memory": 6492874,
        "Result Size": 1252,
        "JVM GC Time": 0,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 800165,
            "Shuffle Write Time": 1169676,
            "Shuffle Records Written": 75539
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 18,
    "Stage Attempt ID": 0,
    "Task Type": "ShuffleMapTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 37,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601069492,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "PROCESS_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601070370,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 450,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 17,
                "Value": 33,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 451,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 8148957,
                "Value": 16948816,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 452,
                "Name": "internal.metrics.executorRunTime",
                "Update": 853,
                "Value": 1184,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 453,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 772466197,
                "Value": 1102628516,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 454,
                "Name": "internal.metrics.resultSize",
                "Update": 1295,
                "Value": 2547,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 455,
                "Name": "internal.metrics.jvmGCTime",
                "Update": 25,
                "Value": 25,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 457,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 458,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 459,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 12423826,
                "Value": 18916700,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 468,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Update": 1533866,
                "Value": 2334031,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 469,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Update": 134089,
                "Value": 209628,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 470,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Update": 1833582,
                "Value": 3003258,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 17,
        "Executor Deserialize CPU Time": 8148957,
        "Executor Run Time": 853,
        "Executor CPU Time": 772466197,
        "Peak Execution Memory": 12423826,
        "Result Size": 1295,
        "JVM GC Time": 25,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 0,
            "Local Blocks Fetched": 0,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 0,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 0,
            "Total Records Read": 0
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 1533866,
            "Shuffle Write Time": 1833582,
            "Shuffle Records Written": 134089
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 0,
            "Records Written": 0
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 18,
        "Stage Attempt ID": 0,
        "Stage Name": "map at main.scala:46",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 67,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"84\",\"name\":\"map\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
                "Callsite": "map at main.scala:46",
                "Parent IDs": [
                    66
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 13,
                "Name": "KafkaRDD",
                "Scope": "{\"id\":\"0_1680601049000\",\"name\":\"kafka 0.10 direct stream [0]\\n@ 17:37:29\"}",
                "Callsite": "createDirectStream at main.scala:31",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 66,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"83\",\"name\":\"flatMap\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
                "Callsite": "flatMap at main.scala:41",
                "Parent IDs": [
                    13
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.map(RDD.scala:413)\nname.spade5.Main$.$anonfun$main$1(main.scala:46)\nname.spade5.Main$.$anonfun$main$1$adapted(main.scala:34)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)\norg.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\norg.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.Try$.apply(Try.scala:210)\norg.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\nscala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\norg.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\njava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\njava.base/java.lang.Thread.run(Thread.java:834)",
        "Submission Time": 1680601069478,
        "Completion Time": 1680601070371,
        "Accumulables": [
            {
                "ID": 450,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 33,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 451,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 16948816,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 452,
                "Name": "internal.metrics.executorRunTime",
                "Value": 1184,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 453,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 1102628516,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 454,
                "Name": "internal.metrics.resultSize",
                "Value": 2547,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 455,
                "Name": "internal.metrics.jvmGCTime",
                "Value": 25,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 457,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 458,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 459,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 18916700,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 468,
                "Name": "internal.metrics.shuffle.write.bytesWritten",
                "Value": 2334031,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 469,
                "Name": "internal.metrics.shuffle.write.recordsWritten",
                "Value": 209628,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 470,
                "Name": "internal.metrics.shuffle.write.writeTime",
                "Value": 3003258,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 19,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 69,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"86\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    68
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 68,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"85\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    67
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            18
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601070374,
        "Accumulables": [],
        "Resource Profile Id": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"86\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
        "spark.job.interruptOnCancel": "false",
        "resource.executor.cores": "1",
        "spark.job.description": "Streaming job from <a href=\"/streaming/batch/?id=1680601049000\">[output operation 0, batch time 17:37:29]</a>",
        "spark.checkpoint.checkpointAllMarkedAncestors": "true",
        "spark.streaming.internal.outputOpId": "0",
        "spark.streaming.internal.batchTime": "1680601049000",
        "spark.rdd.scope.noOverride": "true"
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 19,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 38,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601070393,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskStart",
    "Stage ID": 19,
    "Stage Attempt ID": 0,
    "Task Info": {
        "Task ID": 39,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601070393,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 0,
        "Failed": false,
        "Killed": false,
        "Accumulables": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 19,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 39,
        "Index": 1,
        "Attempt": 0,
        "Partition ID": 1,
        "Launch Time": 1680601070393,
        "Executor ID": "1",
        "Host": "11.11.0.85",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601070603,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 475,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 17,
                "Value": 17,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 476,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 10693970,
                "Value": 10693970,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 477,
                "Name": "internal.metrics.executorRunTime",
                "Update": 184,
                "Value": 184,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 478,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 153347523,
                "Value": 153347523,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 479,
                "Name": "internal.metrics.resultSize",
                "Update": 1780,
                "Value": 1780,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 482,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 483,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 484,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 6895049,
                "Value": 6895049,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 486,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 487,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 1,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 488,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 764700,
                "Value": 764700,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 489,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 490,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 402085,
                "Value": 402085,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 491,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 492,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 104607,
                "Value": 104607,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 498,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 1554179,
                "Value": 1554179,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 499,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 86045,
                "Value": 86045,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 17,
        "Executor Deserialize CPU Time": 10693970,
        "Executor Run Time": 184,
        "Executor CPU Time": 153347523,
        "Peak Execution Memory": 6895049,
        "Result Size": 1780,
        "JVM GC Time": 0,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 764700,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 402085,
            "Total Records Read": 104607
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 1554179,
            "Records Written": 86045
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerTaskEnd",
    "Stage ID": 19,
    "Stage Attempt ID": 0,
    "Task Type": "ResultTask",
    "Task End Reason": {
        "Reason": "Success"
    },
    "Task Info": {
        "Task ID": 38,
        "Index": 0,
        "Attempt": 0,
        "Partition ID": 0,
        "Launch Time": 1680601070393,
        "Executor ID": "0",
        "Host": "11.11.0.87",
        "Locality": "NODE_LOCAL",
        "Speculative": false,
        "Getting Result Time": 0,
        "Finish Time": 1680601070635,
        "Failed": false,
        "Killed": false,
        "Accumulables": [
            {
                "ID": 475,
                "Name": "internal.metrics.executorDeserializeTime",
                "Update": 28,
                "Value": 45,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 476,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Update": 22512550,
                "Value": 33206520,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 477,
                "Name": "internal.metrics.executorRunTime",
                "Update": 205,
                "Value": 389,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 478,
                "Name": "internal.metrics.executorCpuTime",
                "Update": 177024919,
                "Value": 330372442,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 479,
                "Name": "internal.metrics.resultSize",
                "Update": 1780,
                "Value": 3560,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 482,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 483,
                "Name": "internal.metrics.diskBytesSpilled",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 484,
                "Name": "internal.metrics.peakExecutionMemory",
                "Update": 6420827,
                "Value": 13315876,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 486,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 487,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Update": 1,
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 488,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Update": 398080,
                "Value": 1162780,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 489,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 490,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Update": 769166,
                "Value": 1171251,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 491,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Update": 0,
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 492,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Update": 105021,
                "Value": 209628,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 498,
                "Name": "internal.metrics.output.bytesWritten",
                "Update": 1548088,
                "Value": 3102267,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 499,
                "Name": "internal.metrics.output.recordsWritten",
                "Update": 86222,
                "Value": 172267,
                "Internal": true,
                "Count Failed Values": true
            }
        ]
    },
    "Task Executor Metrics": {
        "JVMHeapMemory": 0,
        "JVMOffHeapMemory": 0,
        "OnHeapExecutionMemory": 0,
        "OffHeapExecutionMemory": 0,
        "OnHeapStorageMemory": 0,
        "OffHeapStorageMemory": 0,
        "OnHeapUnifiedMemory": 0,
        "OffHeapUnifiedMemory": 0,
        "DirectPoolMemory": 0,
        "MappedPoolMemory": 0,
        "ProcessTreeJVMVMemory": 0,
        "ProcessTreeJVMRSSMemory": 0,
        "ProcessTreePythonVMemory": 0,
        "ProcessTreePythonRSSMemory": 0,
        "ProcessTreeOtherVMemory": 0,
        "ProcessTreeOtherRSSMemory": 0,
        "MinorGCCount": 0,
        "MinorGCTime": 0,
        "MajorGCCount": 0,
        "MajorGCTime": 0,
        "TotalGCTime": 0
    },
    "Task Metrics": {
        "Executor Deserialize Time": 28,
        "Executor Deserialize CPU Time": 22512550,
        "Executor Run Time": 205,
        "Executor CPU Time": 177024919,
        "Peak Execution Memory": 6420827,
        "Result Size": 1780,
        "JVM GC Time": 0,
        "Result Serialization Time": 0,
        "Memory Bytes Spilled": 0,
        "Disk Bytes Spilled": 0,
        "Shuffle Read Metrics": {
            "Remote Blocks Fetched": 1,
            "Local Blocks Fetched": 1,
            "Fetch Wait Time": 0,
            "Remote Bytes Read": 398080,
            "Remote Bytes Read To Disk": 0,
            "Local Bytes Read": 769166,
            "Total Records Read": 105021
        },
        "Shuffle Write Metrics": {
            "Shuffle Bytes Written": 0,
            "Shuffle Write Time": 0,
            "Shuffle Records Written": 0
        },
        "Input Metrics": {
            "Bytes Read": 0,
            "Records Read": 0
        },
        "Output Metrics": {
            "Bytes Written": 1548088,
            "Records Written": 86222
        },
        "Updated Blocks": []
    }
}
{
    "Event": "SparkListenerStageCompleted",
    "Stage Info": {
        "Stage ID": 19,
        "Stage Attempt ID": 0,
        "Stage Name": "runJob at SparkHadoopWriter.scala:83",
        "Number of Tasks": 2,
        "RDD Info": [
            {
                "RDD ID": 69,
                "Name": "MapPartitionsRDD",
                "Scope": "{\"id\":\"86\",\"name\":\"saveAsTextFile\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
                "Callsite": "saveAsTextFile at main.scala:48",
                "Parent IDs": [
                    68
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 68,
                "Name": "ShuffledRDD",
                "Scope": "{\"id\":\"85\",\"name\":\"reduceByKey\",\"parent\":{\"id\":\"1_1680601049000\",\"name\":\"foreachRDD @ 17:37:29\"}}",
                "Callsite": "reduceByKey at main.scala:46",
                "Parent IDs": [
                    67
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "UNORDERED",
                "Number of Partitions": 2,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [
            18
        ],
        "Details": "org.apache.spark.SparkContext.runJob(SparkContext.scala:2291)\norg.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)\norg.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)\nscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\norg.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\norg.apache.spark.rdd.RDD.withScope(RDD.scala:406)\norg.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)",
        "Submission Time": 1680601070374,
        "Completion Time": 1680601070636,
        "Accumulables": [
            {
                "ID": 475,
                "Name": "internal.metrics.executorDeserializeTime",
                "Value": 45,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 476,
                "Name": "internal.metrics.executorDeserializeCpuTime",
                "Value": 33206520,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 477,
                "Name": "internal.metrics.executorRunTime",
                "Value": 389,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 478,
                "Name": "internal.metrics.executorCpuTime",
                "Value": 330372442,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 479,
                "Name": "internal.metrics.resultSize",
                "Value": 3560,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 482,
                "Name": "internal.metrics.memoryBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 483,
                "Name": "internal.metrics.diskBytesSpilled",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 484,
                "Name": "internal.metrics.peakExecutionMemory",
                "Value": 13315876,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 486,
                "Name": "internal.metrics.shuffle.read.remoteBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 487,
                "Name": "internal.metrics.shuffle.read.localBlocksFetched",
                "Value": 2,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 488,
                "Name": "internal.metrics.shuffle.read.remoteBytesRead",
                "Value": 1162780,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 489,
                "Name": "internal.metrics.shuffle.read.remoteBytesReadToDisk",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 490,
                "Name": "internal.metrics.shuffle.read.localBytesRead",
                "Value": 1171251,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 491,
                "Name": "internal.metrics.shuffle.read.fetchWaitTime",
                "Value": 0,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 492,
                "Name": "internal.metrics.shuffle.read.recordsRead",
                "Value": 209628,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 498,
                "Name": "internal.metrics.output.bytesWritten",
                "Value": 3102267,
                "Internal": true,
                "Count Failed Values": true
            },
            {
                "ID": 499,
                "Name": "internal.metrics.output.recordsWritten",
                "Value": 172267,
                "Internal": true,
                "Count Failed Values": true
            }
        ],
        "Resource Profile Id": 0
    }
}
{
    "Event": "SparkListenerJobEnd",
    "Job ID": 9,
    "Completion Time": 1680601070637,
    "Job Result": {
        "Result": "JobSucceeded"
    }
}